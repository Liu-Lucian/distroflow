#!/usr/bin/env python3
"""
Substackå›ç­”ç³»ç»Ÿé€»è¾‘æµ‹è¯• - çº¯æœ¬åœ°æµ‹è¯•ï¼Œæ— éœ€æµè§ˆå™¨

åŠŸèƒ½ï¼š
1. æµ‹è¯•è¯„è®ºè¿‡æ»¤é€»è¾‘ï¼ˆshould_answer_commentï¼‰
2. æµ‹è¯•AIå›ç­”ç”Ÿæˆï¼ˆgenerate_answerï¼‰
3. äº¤äº’å¼æµ‹è¯•æ¨¡å¼ï¼ˆè¾“å…¥è¯„è®ºï¼Œçœ‹AIå¦‚ä½•å›ç­”ï¼‰
4. æ‰¹é‡æµ‹è¯•å¤šç§è¯„è®ºç±»å‹

æ— éœ€ç™»å½•ï¼Œæ— éœ€æµè§ˆå™¨ï¼Œçº¯æœ¬åœ°æµ‹è¯•AIé€»è¾‘
"""

import os
from openai import OpenAI
import logging
from typing import List, Dict
import json

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))


class SubstackAnswerTester:
    """Substackå›ç­”é€»è¾‘æµ‹è¯•å™¨"""

    def __init__(self):
        self.test_results = []

    def should_answer_comment(self, comment_text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å›ç­”è¿™æ¡è¯„è®ºï¼ˆä¸substack_answer_bot.pyç›¸åŒé€»è¾‘ï¼‰
        """
        comment_lower = comment_text.lower()

        # å¤ªçŸ­çš„è¯„è®ºä¸å›ç­”
        if len(comment_text) < 10:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é—®é¢˜è¯
        question_keywords = ['?', 'ï¼Ÿ', 'how', 'why', 'what', 'when', 'where', 'who',
                           'can', 'could', 'would', 'should', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ',
                           'ä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'èƒ½ä¸èƒ½', 'å¯ä»¥']

        has_question = any(keyword in comment_lower for keyword in question_keywords)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³ä¸»é¢˜
        relevant_topics = ['interview', 'job', 'career', 'ai', 'resume', 'cv',
                          'hiring', 'recruiter', 'é¢è¯•', 'å·¥ä½œ', 'èŒä¸š', 'ç®€å†',
                          'æ±‚èŒ', 'tech', 'coding', 'programming', 'æŠ€æœ¯']

        is_relevant = any(topic in comment_lower for topic in relevant_topics)

        # é—®é¢˜ OR ç›¸å…³ä¸»é¢˜éƒ½å¯ä»¥å›ç­”
        return has_question or is_relevant

    def generate_answer(self, comment_text: str, context: str = "") -> str:
        """
        Generate answer (same logic as substack_answer_bot.py)
        """
        product_context = """
You are the founder of HireMeAI (https://interviewasssistant.com), an AI-powered real-time interview assistant.

Product core features:
- Voice recognition (95%+ accuracy)
- Speaker identification (92% accuracy)
- Real-time AI answer generation (<1s latency)
- STAR framework interview optimization

Your response style requirements:
âœ… Warm, concise, practical
âœ… Use casual internet language naturally (e.g., "damn", "ngl", "tbh", "lowkey", "fr")
âœ… Answer seemingly "unrelated" but relevant questions (interview tips, AI applications, career advice)
âœ… Don't be overly enthusiastic, don't hard-sell the product
âœ… If very relevant, you can naturally mention HireMeAI, but it's not required

âŒ Avoid:
- Long-winded responses
- Overly formal tone
- Direct product pitches
- Excessive praise or enthusiasm
"""

        prompt = f"""{product_context}

Article context:
{context if context else "No specific context"}

Comment:
{comment_text}

Generate a brief, valuable response in ENGLISH (50-150 words):
- Directly answer the core question
- Share practical insights or experience
- Natural, warm but not over-the-top tone
- Use casual internet language appropriately
- If highly relevant, casually mention HireMeAI (https://interviewasssistant.com), but don't force it

Output ONLY the response text in ENGLISH, no additional explanation:"""

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.8,
                max_tokens=200
            )

            answer = response.choices[0].message.content.strip()
            return answer

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}")
            return None

    def test_single_comment(self, comment: str, context: str = "", show_details: bool = True):
        """
        æµ‹è¯•å•æ¡è¯„è®º

        Args:
            comment: è¯„è®ºå†…å®¹
            context: æ–‡ç« ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        if show_details:
            logger.info("\n" + "="*80)
            logger.info("ğŸ“ è¯„è®º:")
            logger.info(f"   {comment}")
            logger.info("-"*80)

        # æ­¥éª¤1: åˆ¤æ–­æ˜¯å¦åº”è¯¥å›ç­”
        should_answer = self.should_answer_comment(comment)

        if show_details:
            logger.info(f"ğŸ¤” æ˜¯å¦åº”è¯¥å›ç­”: {'âœ… æ˜¯' if should_answer else 'âŒ å¦'}")

        if not should_answer:
            if show_details:
                logger.info("   â„¹ï¸  è·³è¿‡åŸå› : ä¸ç¬¦åˆå›ç­”æ¡ä»¶ï¼ˆå¤ªçŸ­/ä¸ç›¸å…³/æ— é—®é¢˜ï¼‰")
            return {
                'comment': comment,
                'should_answer': False,
                'answer': None,
                'reason': 'ä¸ç¬¦åˆå›ç­”æ¡ä»¶'
            }

        # æ­¥éª¤2: ç”Ÿæˆå›ç­”
        if show_details:
            logger.info("ğŸ¤– æ­£åœ¨ç”ŸæˆAIå›ç­”...")

        answer = self.generate_answer(comment, context)

        if show_details:
            logger.info("-"*80)
            if answer:
                logger.info("ğŸ’¬ ç”Ÿæˆçš„å›ç­”:")
                logger.info(f"   {answer}")
                logger.info(f"   ï¼ˆå­—æ•°: {len(answer)} å­—ç¬¦ï¼‰")
            else:
                logger.info("âŒ å›ç­”ç”Ÿæˆå¤±è´¥")
            logger.info("="*80)

        result = {
            'comment': comment,
            'should_answer': True,
            'answer': answer,
            'char_count': len(answer) if answer else 0
        }

        self.test_results.append(result)
        return result

    def batch_test_comments(self, test_cases: List[Dict]):
        """
        æ‰¹é‡æµ‹è¯•å¤šæ¡è¯„è®º

        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ [{'comment': '...', 'context': '...', 'expect_answer': True/False}, ...]
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸ§ª æ‰¹é‡æµ‹è¯•æ¨¡å¼")
        logger.info("="*80)
        logger.info(f"æ€»å…± {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹\n")

        passed = 0
        failed = 0

        for i, case in enumerate(test_cases, 1):
            comment = case['comment']
            context = case.get('context', '')
            expect_answer = case.get('expect_answer', True)

            logger.info(f"\n--- æµ‹è¯• {i}/{len(test_cases)} ---")
            logger.info(f"è¯„è®º: {comment[:60]}...")
            logger.info(f"é¢„æœŸ: {'åº”è¯¥å›ç­”' if expect_answer else 'åº”è¯¥è·³è¿‡'}")

            result = self.test_single_comment(comment, context, show_details=False)

            # éªŒè¯ç»“æœ
            if result['should_answer'] == expect_answer:
                logger.info(f"âœ… é€šè¿‡")
                if result['should_answer'] and result['answer']:
                    logger.info(f"   å›ç­”: {result['answer'][:80]}...")
                passed += 1
            else:
                logger.info(f"âŒ å¤±è´¥ï¼ˆé¢„æœŸ{expect_answer}ï¼Œå®é™…{result['should_answer']}ï¼‰")
                failed += 1

        # æ€»ç»“
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“")
        logger.info("="*80)
        logger.info(f"âœ… é€šè¿‡: {passed}/{len(test_cases)}")
        logger.info(f"âŒ å¤±è´¥: {failed}/{len(test_cases)}")
        logger.info(f"é€šè¿‡ç‡: {passed/len(test_cases)*100:.1f}%")
        logger.info("="*80)

    def interactive_test(self):
        """
        äº¤äº’å¼æµ‹è¯•æ¨¡å¼ - æ‰‹åŠ¨è¾“å…¥è¯„è®ºï¼Œå®æ—¶çœ‹AIå›ç­”
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸ® äº¤äº’å¼æµ‹è¯•æ¨¡å¼")
        logger.info("="*80)
        logger.info("è¾“å…¥è¯„è®ºï¼ŒæŒ‰EnteræŸ¥çœ‹AIå›ç­”")
        logger.info("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        logger.info("è¾“å…¥ 'examples' æŸ¥çœ‹ç¤ºä¾‹è¯„è®º")
        logger.info("="*80 + "\n")

        while True:
            try:
                comment = input("ğŸ’¬ è¯„è®ºå†…å®¹: ").strip()

                if not comment:
                    continue

                if comment.lower() in ['quit', 'exit', 'q']:
                    logger.info("\nğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                    break

                if comment.lower() == 'examples':
                    self._show_example_comments()
                    continue

                # æµ‹è¯•è¯„è®º
                self.test_single_comment(comment)

            except KeyboardInterrupt:
                logger.info("\n\nğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                break
            except EOFError:
                break

    def _show_example_comments(self):
        """æ˜¾ç¤ºç¤ºä¾‹è¯„è®º"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ“‹ ç¤ºä¾‹è¯„è®ºï¼ˆå¤åˆ¶ç²˜è´´æµ‹è¯•ï¼‰")
        logger.info("="*80)

        examples = [
            "How do you handle nervous candidates during interviews?",
            "This is amazing! Does it work for non-tech interviews?",
            "Damn, this is impressive! How did you get 92% accuracy on speaker ID?",
            "What's the latency? I need real-time responses.",
            "Great article!",  # Should skip
            "Thanks for sharing",  # Should skip
            "Ngl, I've failed 10+ behavioral interviews. Does the STAR framework really help?",
            "Can AI really understand behavioral interview questions?",
            "Are you using GPT-4 or did you train your own model?",
            "I tried it and the latency felt high. How did you optimize it?"
        ]

        for i, example in enumerate(examples, 1):
            logger.info(f"{i}. {example}")

        logger.info("="*80 + "\n")


def run_preset_tests():
    """è¿è¡Œé¢„è®¾æµ‹è¯•ç”¨ä¾‹"""
    logger.info("\n" + "ğŸ¯"*20)
    logger.info("Substack å›ç­”ç³»ç»Ÿé€»è¾‘æµ‹è¯•")
    logger.info("ğŸ¯"*20 + "\n")

    tester = SubstackAnswerTester()

    # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        # åº”è¯¥å›ç­”çš„è¯„è®ºï¼ˆåŒ…å«é—®é¢˜ï¼‰
        {
            'comment': 'How do you handle nervous candidates who freeze during behavioral questions?',
            'expect_answer': True
        },
        {
            'comment': 'What\'s the latency like? Does the AI respond fast enough to be useful in real interviews?',
            'expect_answer': True
        },
        {
            'comment': 'Damn, this is impressive! Does it work for technical interviews too?',
            'expect_answer': True
        },
        {
            'comment': 'What do you do when you get nervous during interviews? Any good tips?',
            'expect_answer': True
        },

        # Should answer (contains relevant topics)
        {
            'comment': 'I struggle with behavioral interviews. This could be a game changer for job seekers.',
            'expect_answer': True
        },
        {
            'comment': 'As a recruiter, I\'m curious how AI is changing the interview preparation landscape.',
            'expect_answer': True
        },
        {
            'comment': 'Currently prepping for tech interviews and feeling so stressed tbh',
            'expect_answer': True
        },

        # åº”è¯¥è·³è¿‡çš„è¯„è®ºï¼ˆå¤ªçŸ­ï¼‰
        {
            'comment': 'Great!',
            'expect_answer': False
        },
        {
            'comment': 'Thanks',
            'expect_answer': False
        },

        # åº”è¯¥è·³è¿‡çš„è¯„è®ºï¼ˆä¸ç›¸å…³ï¼‰
        {
            'comment': 'I love pizza! What\'s your favorite food?',
            'expect_answer': False
        },
        {
            'comment': 'Nice weather today, isn\'t it?',
            'expect_answer': False
        },

        # è¾¹ç•Œæƒ…å†µ
        {
            'comment': 'Interesting article, but not sure if AI can really help with interviews.',
            'expect_answer': True  # åŒ…å«"interview"
        },
        {
            'comment': 'This is really well written! Keep up the good work building in public.',
            'expect_answer': False  # çº¯èµç¾ï¼Œæ— é—®é¢˜
        },
    ]

    # è¿è¡Œæ‰¹é‡æµ‹è¯•
    logger.info("=" * 80)
    logger.info("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹é‡æµ‹è¯•ï¼ˆéªŒè¯è¿‡æ»¤é€»è¾‘ï¼‰")
    logger.info("=" * 80)
    tester.batch_test_comments(test_cases)

    # è¿è¡Œè¯¦ç»†æµ‹è¯•ï¼ˆå±•ç¤ºAIå›ç­”ï¼‰
    logger.info("\n\n" + "=" * 80)
    logger.info("ç¬¬äºŒéƒ¨åˆ†ï¼šè¯¦ç»†æµ‹è¯•ï¼ˆæŸ¥çœ‹AIç”Ÿæˆçš„å›ç­”ï¼‰")
    logger.info("=" * 80)
    logger.info("ä»¥ä¸‹æ˜¯AIä¸ºçœŸå®è¯„è®ºç”Ÿæˆçš„å›ç­”ç¤ºä¾‹ï¼š\n")

    detailed_test_cases = [
        {
            'comment': 'How do you handle the latency issue? 1 second seems fast but is it fast enough for live interviews?',
            'context': 'Article about achieving <1s response time in HireMeAI'
        },
        {
            'comment': 'Damn, how did you get 92% accuracy on speaker ID? I tried a few voice recognition tools and they were terrible.',
            'context': 'Article about speaker identification breakthrough'
        },
        {
            'comment': 'As someone who has failed 10+ behavioral interviews, I wish I had this earlier. Does it help with the "Tell me about yourself" question?',
            'context': 'Article about common interview mistakes'
        },
        {
            'comment': 'I\'m a recruiter and honestly this is both exciting and scary. How do you ensure candidates use it ethically?',
            'context': 'Article about AI in interviews'
        },
    ]

    for case in detailed_test_cases:
        tester.test_single_comment(case['comment'], case.get('context', ''))

    # ä¿å­˜æµ‹è¯•ç»“æœ
    with open('substack_answer_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(tester.test_results, f, indent=2, ensure_ascii=False)

    logger.info(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: substack_answer_test_results.json")

    return tester


def main():
    """ä¸»å‡½æ•°"""
    import sys

    logger.info("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼ï¼š")
    logger.info("1. è¿è¡Œé¢„è®¾æµ‹è¯•ç”¨ä¾‹ï¼ˆæ¨èï¼‰")
    logger.info("2. äº¤äº’å¼æµ‹è¯•æ¨¡å¼ï¼ˆæ‰‹åŠ¨è¾“å…¥è¯„è®ºï¼‰")
    logger.info("3. è¿è¡Œå…¨éƒ¨æµ‹è¯•")

    try:
        choice = input("\né€‰æ‹© (1/2/3): ").strip()
    except (EOFError, KeyboardInterrupt):
        logger.info("\nå·²å–æ¶ˆ")
        return

    tester = SubstackAnswerTester()

    if choice == '1':
        run_preset_tests()

    elif choice == '2':
        tester.interactive_test()

    elif choice == '3':
        run_preset_tests()
        logger.info("\n\n")
        response = input("æ˜¯å¦ç»§ç»­è¿›å…¥äº¤äº’å¼æµ‹è¯•ï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            tester.interactive_test()

    else:
        logger.info("âŒ æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    # æ£€æŸ¥API Key
    if not os.environ.get('OPENAI_API_KEY'):
        logger.error("\nâŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        logger.error("è¯·è¿è¡Œ: export OPENAI_API_KEY='your-key-here'")
        exit(1)

    logger.info("âœ… OpenAI API Key å·²è®¾ç½®")

    main()
