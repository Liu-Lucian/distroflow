#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯• Medium å†…å®¹ç”Ÿæˆ - ç®€åŒ–ç‰ˆæœ¬
ä¸ä½¿ç”¨å¤æ‚çš„ JSONï¼Œç›´æ¥è¿”å› Markdown
"""

import sys
sys.path.insert(0, 'src')

from medium_poster import MediumPoster
import anthropic
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç®€å•æµ‹è¯•ï¼šæ‰‹åŠ¨åˆ›å»ºä¸€ç¯‡æ–‡ç« 
test_content = {
    'title': 'Building HireMeAI: Day 1 - System Architecture',
    'subtitle': 'A technical deep dive into our AI interview assistant',
    'content': '''## Introduction

When building HireMeAI (å³ç­”ä¾ ), we faced a fundamental challenge: how do you create a real-time AI interview assistant that responds in less than 1 second?

Today, I'll share the technical architecture decisions that power our system.

## The Core Challenge

Real-time interview assistance requires:
- Speech recognition with 95%+ accuracy
- Intelligent speaker identification
- Sub-second response latency
- Context-aware answer generation

## Our Technical Stack

### AI Engine
- **OpenAI GPT-4**: High-quality content generation
- **Azure Speech Services**: Enterprise-grade recognition
- **Picovoice Eagle**: Professional speaker identification
- **ChromaDB**: Vector semantic search

### Performance Optimization
- **Dual-level caching**: Memory + disk persistence
- **Streaming responses**: Server-Sent Events
- **Smart pre-computation**: 80% faster for common questions
- **Batch processing**: Reduced API costs by 70%

## Key Metrics

Our optimizations achieved:
- Embedding generation: 1.459s â†’ 0.3s (80% improvement)
- First response latency: 2.7s â†’ 1.0s (60% improvement)
- Cache hit rate: 90%+ for common questions
- API cost savings: 70%+

## What's Next

Tomorrow I'll dive into the speech recognition pipeline and how we achieved 95%+ accuracy.

---

Building this has been an incredible journey. The key lesson? Performance optimization isn't optional for real-time AI systems - it's essential.

Learn more: https://interviewasssistant.com
Contact: liu.lucian6@gmail.com

#AI #BuildInPublic #TechArchitecture #InterviewPrep #MachineLearning''',
    'tags': ['AI', 'BuildInPublic', 'TechArchitecture', 'InterviewPrep', 'MachineLearning']
}

logger.info("ğŸ¨ å¼€å§‹æµ‹è¯• Medium å‘å¸ƒ...")
logger.info(f"æ ‡é¢˜: {test_content['title']}")
logger.info(f"å­—æ•°: {len(test_content['content'].split())} words")

poster = MediumPoster()

try:
    logger.info("ğŸŒ è®¾ç½®æµè§ˆå™¨...")
    poster.setup_browser(headless=False)

    logger.info("ğŸ” éªŒè¯ç™»å½•...")
    if not poster.verify_login():
        logger.error("âŒ ç™»å½•éªŒè¯å¤±è´¥ï¼Œè¯·å…ˆè¿è¡Œ medium_login_and_save_auth.py")
        sys.exit(1)

    logger.info("âœ… ç™»å½•éªŒè¯æˆåŠŸ")

    logger.info("ğŸ“¤ å¼€å§‹å‘å¸ƒ...")
    success = poster.create_post(test_content)

    if success:
        logger.info("=" * 80)
        logger.info("âœ… Medium æ–‡ç« å‘å¸ƒæˆåŠŸï¼")
        logger.info("=" * 80)
    else:
        logger.error("âŒ å‘å¸ƒå¤±è´¥")

except Exception as e:
    logger.error(f"âŒ é”™è¯¯: {str(e)}")
    import traceback
    traceback.print_exc()
finally:
    try:
        input("\næŒ‰ Enter å…³é—­æµè§ˆå™¨...")
    except EOFError:
        pass
    poster.close_browser()
