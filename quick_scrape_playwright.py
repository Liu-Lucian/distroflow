#!/usr/bin/env python3
"""
å¿«é€Ÿçˆ¬å–è„šæœ¬ - Playwright ç‰ˆæœ¬ï¼ˆä½¿ç”¨ä¿å­˜çš„ç™»å½•æ€ï¼‰
Quick scrape with Playwright (using saved authentication)

ä½¿ç”¨å‰è¯·å…ˆè¿è¡Œä¸€æ¬¡ï¼špython login_and_save_auth.py
Before using, run once: python login_and_save_auth.py
"""

import sys
import os
from src.twitter_scraper_playwright import TwitterPlaywrightScraper
import pandas as pd

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³• / Usage: python quick_scrape_playwright.py <ç”¨æˆ·å> [æ•°é‡]")
        print("ç¤ºä¾‹ / Example: python quick_scrape_playwright.py elonmusk 50")
        print()
        print("âš ï¸  é¦–æ¬¡ä½¿ç”¨å‰è¯·å…ˆè¿è¡Œï¼špython login_and_save_auth.py")
        print("   Before first use, run: python login_and_save_auth.py")
        sys.exit(1)

    target_user = sys.argv[1]
    count = int(sys.argv[2]) if len(sys.argv) > 2 else 50

    # Check if auth.json exists
    if not os.path.exists("auth.json"):
        print("=" * 60)
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° auth.json æ–‡ä»¶")
        print("   Error: auth.json file not found")
        print()
        print("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä¿å­˜ç™»å½•çŠ¶æ€ï¼š")
        print("Please run the following command to save login state first:")
        print()
        print("   python login_and_save_auth.py")
        print()
        print("åªéœ€è¦è¿è¡Œä¸€æ¬¡ï¼Œä¹‹åå°±å¯ä»¥è‡ªåŠ¨ç™»å½•äº†ï¼")
        print("You only need to run it once, then you can auto-login!")
        print("=" * 60)
        sys.exit(1)

    print("=" * 60)
    print("Twitter å¿«é€Ÿçˆ¬è™« (Playwright + ä¿å­˜çš„ç™»å½•æ€)")
    print("Twitter Quick Scraper (Playwright + Saved Auth)")
    print("=" * 60)
    print(f"ç›®æ ‡ / Target: @{target_user}")
    print(f"æ•°é‡ / Count: {count} ç²‰ä¸ / followers")
    print("=" * 60)
    print()

    try:
        # Create scraper with saved authentication
        scraper = TwitterPlaywrightScraper(headless=False, auth_file="auth.json")
        scraper.start()

        print("ğŸ” å¼€å§‹çˆ¬å–ç²‰ä¸ / Starting to scrape followers...")
        print()

        followers = scraper.get_followers(
            username=target_user,
            max_followers=count,
            extract_emails=True
        )

        if followers:
            print()
            print("=" * 60)
            print(f"âœ“ æˆåŠŸçˆ¬å– / Successfully scraped: {len(followers)} ä¸ªç²‰ä¸ / followers")
            print("=" * 60)

            # Statistics
            emails = [f for f in followers if f.get('email')]
            print(f"ğŸ“§ æ‰¾åˆ°é‚®ç®± / Emails found: {len(emails)} ({len(emails)/len(followers)*100:.1f}%)")
            print()

            # Show sample followers with emails
            if emails:
                print("æœ‰é‚®ç®±çš„ç²‰ä¸æ ·ä¾‹ / Sample followers with emails:")
                for i, f in enumerate(emails[:5], 1):
                    print(f"{i}. @{f['username']} - {f['email']}")
                print()

            # Export to CSV
            os.makedirs('exports', exist_ok=True)
            df = pd.DataFrame(followers)
            filename = f'exports/twitter_{target_user}_{count}_playwright.csv'
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"âœ“ æ•°æ®å·²å¯¼å‡º / Data exported: {filename}")
            print()
            print("ğŸ‰ å®Œæˆ / Done!")
        else:
            print("=" * 60)
            print("âŒ æœªè·å–åˆ°æ•°æ® / No data retrieved")
            print()
            print("å¯èƒ½çš„åŸå›  / Possible reasons:")
            print("1. ç™»å½•çŠ¶æ€å·²è¿‡æœŸ / Login state expired")
            print("   è§£å†³ / Solution: é‡æ–°è¿è¡Œ / Re-run 'python login_and_save_auth.py'")
            print()
            print("2. ç”¨æˆ·åä¸å­˜åœ¨æˆ–è´¦å·è¢«ä¿æŠ¤ / Username doesn't exist or account is protected")
            print("   è§£å†³ / Solution: æ£€æŸ¥ç”¨æˆ·åæ‹¼å†™ / Check username spelling")
            print()
            print("3. Twitter é¡µé¢ç»“æ„å˜åŒ– / Twitter page structure changed")
            print("   è§£å†³ / Solution: è”ç³»å¼€å‘è€…æ›´æ–°ä»£ç  / Contact developer for code update")
            print("=" * 60)

    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯ / Error: {e}")
        print()
        print("è¯·å…ˆè¿è¡Œ / Please run first:")
        print("   python login_and_save_auth.py")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ / User interrupted")

    except Exception as e:
        print(f"âŒ é”™è¯¯ / Error: {e}")
        import traceback
        traceback.print_exc()

    finally:
        if 'scraper' in locals():
            scraper.close()


if __name__ == "__main__":
    main()
