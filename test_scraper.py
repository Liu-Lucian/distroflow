#!/usr/bin/env python3
"""å¿«é€Ÿæµ‹è¯•çˆ¬è™« / Quick test scraper"""

from src.twitter_scraper import TwitterWebScraper
import pandas as pd

print("="*60)
print("Twitter Web Scraper - Quick Test")
print("="*60)
print()

# åˆ›å»ºçˆ¬è™«ï¼ˆæ˜¾ç¤ºæµè§ˆå™¨ï¼‰
print("1. åˆå§‹åŒ–çˆ¬è™«...")
scraper = TwitterWebScraper(headless=False)  # æ˜¾ç¤ºæµè§ˆå™¨

try:
    # çˆ¬å–å°‘é‡ç²‰ä¸æµ‹è¯•
    print("2. çˆ¬å– @elonmusk çš„å‰10ä¸ªç²‰ä¸...")
    print()
    
    followers = scraper.get_followers(
        username="elonmusk",
        max_followers=10,
        extract_emails=True
    )
    
    print()
    print("="*60)
    print(f"âœ“ æˆåŠŸçˆ¬å– {len(followers)} ä¸ªç²‰ä¸")
    print("="*60)
    print()
    
    # æ˜¾ç¤ºç»“æœ
    for i, f in enumerate(followers, 1):
        print(f"{i}. @{f['username']}")
        print(f"   å§“å: {f['name']}")
        if f.get('email'):
            print(f"   ğŸ“§ é‚®ç®±: {f['email']}")
        print(f"   ç®€ä»‹: {f['bio'][:60]}...")
        print()
    
    # ç»Ÿè®¡
    if followers:
        emails = [f for f in followers if f.get('email')]
        print(f"é‚®ç®±æå–ç‡: {len(emails)}/{len(followers)} ({len(emails)/len(followers)*100:.1f}%)")
    else:
        print("âš ï¸  æ²¡æœ‰çˆ¬å–åˆ°ç²‰ä¸æ•°æ®")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. Twitteré¡µé¢ç»“æ„å·²æ›´æ–°")
        print("2. éœ€è¦ç™»å½•æ‰èƒ½è®¿é—®")
        print("3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("\nå»ºè®®:")
        print("â€¢ æ£€æŸ¥æµè§ˆå™¨çª—å£æ˜¯å¦æ­£å¸¸æ‰“å¼€")
        print("â€¢ å°è¯•æ‰‹åŠ¨è®¿é—® https://twitter.com/elonmusk/followers")
        print("â€¢ å¦‚æœéœ€è¦ç™»å½•ï¼Œè¯·æ›´æ–°ä»£ç æ·»åŠ ç™»å½•åŠŸèƒ½")
    print()
    
    # å¯¼å‡º
    if followers:
        df = pd.DataFrame(followers)
        df.to_csv('test_followers.csv', index=False, encoding='utf-8-sig')
        print("âœ“ æ•°æ®å·²å¯¼å‡ºåˆ°: test_followers.csv")
        print()
        print("æµ‹è¯•æˆåŠŸï¼ğŸ‰")
    else:
        print("âŒ æµ‹è¯•æœªèƒ½è·å–æ•°æ®ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹çš„å»ºè®®")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()

finally:
    scraper.close()
    print("\nå®Œæˆï¼")
