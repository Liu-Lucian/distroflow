#!/usr/bin/env python3
"""
SEOæŒç»­ç›‘æ§ç³»ç»Ÿ
- è‡ªåŠ¨æ£€æµ‹å†…å®¹è´¨é‡é—®é¢˜
- è‡ªåŠ¨ä¿®å¤å¹¶é‡æ–°è¿è¡Œ
- æŒç»­ä¼˜åŒ–å’Œæ›´æ–°å†…å®¹
"""

import os
import sys
import time
import json
import subprocess
import re
from datetime import datetime
from pathlib import Path

# å·¥ä½œç›®å½•
WORK_DIR = "/Users/l.u.c/my-app/MarketingMind AI"
os.chdir(WORK_DIR)

# ç›‘æ§é…ç½®
CHECK_INTERVAL = 300  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
CONTENT_DIR = "seo_data/content"
PUBLISHED_CONTENT_FILE = "seo_data/published_content.json"
WORKFLOW_STATE_FILE = "seo_data/workflow_state.json"

class SEOMonitor:
    def __init__(self):
        self.run_count = 0
        self.fix_count = 0
        self.last_check = None

    def log(self, message, level="INFO"):
        """æ—¥å¿—è¾“å‡º"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        prefix = {
            "INFO": "â„¹ï¸ ",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸ ",
            "ERROR": "âŒ",
            "FIX": "ğŸ”§"
        }.get(level, "")
        print(f"[{timestamp}] {prefix} {message}")
        sys.stdout.flush()

    def check_html_quality(self, filepath):
        """æ£€æŸ¥HTMLæ–‡ä»¶è´¨é‡"""
        issues = []

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ£€æŸ¥1: Markdown artifacts
            if '```markdown' in content or '```\n' in content[:1000]:
                issues.append({
                    'type': 'markdown_artifacts',
                    'severity': 'high',
                    'description': 'Found markdown code block markers in HTML'
                })

            # æ£€æŸ¥2: HireMeAIå“ç‰ŒæåŠ
            hiremeai_count = content.lower().count('hiremeai') + content.lower().count('å³ç­”ä¾ ')
            if hiremeai_count < 3:
                issues.append({
                    'type': 'weak_branding',
                    'severity': 'medium',
                    'description': f'HireMeAI mentioned only {hiremeai_count} times (expected â‰¥3)'
                })

            # æ£€æŸ¥3: CTAé“¾æ¥
            cta_count = content.count('https://interviewasssistant.com')
            if cta_count < 2:
                issues.append({
                    'type': 'missing_cta',
                    'severity': 'high',
                    'description': f'Only {cta_count} CTAs found (expected â‰¥2)'
                })

            # æ£€æŸ¥4: Schema markup
            if '"@context": "https://schema.org"' not in content:
                issues.append({
                    'type': 'missing_schema',
                    'severity': 'medium',
                    'description': 'Missing Schema.org markup'
                })

            # æ£€æŸ¥5: Metaæè¿°
            if 'meta name="description"' not in content:
                issues.append({
                    'type': 'missing_meta',
                    'severity': 'high',
                    'description': 'Missing meta description'
                })

            # æ£€æŸ¥6: HTMLç»“æ„é—®é¢˜
            # ç®€å•æ£€æŸ¥ï¼š</p>åº”è¯¥åœ¨<p>ä¹‹å
            p_open = content.count('<p>')
            p_close = content.count('</p>')
            if abs(p_open - p_close) > 2:
                issues.append({
                    'type': 'html_structure',
                    'severity': 'medium',
                    'description': f'Unbalanced <p> tags: {p_open} open, {p_close} close'
                })

        except Exception as e:
            issues.append({
                'type': 'read_error',
                'severity': 'critical',
                'description': f'Cannot read file: {str(e)}'
            })

        return issues

    def check_all_content(self):
        """æ£€æŸ¥æ‰€æœ‰å‘å¸ƒçš„å†…å®¹"""
        self.log("ğŸ” Scanning all published content...")

        if not os.path.exists(CONTENT_DIR):
            self.log("Content directory not found!", "ERROR")
            return []

        html_files = list(Path(CONTENT_DIR).glob("*.html"))
        self.log(f"   Found {len(html_files)} HTML files")

        all_issues = []
        for filepath in html_files:
            issues = self.check_html_quality(filepath)
            if issues:
                all_issues.append({
                    'file': filepath.name,
                    'path': str(filepath),
                    'issues': issues
                })

        return all_issues

    def auto_fix_content(self):
        """è‡ªåŠ¨ä¿®å¤å†…å®¹è´¨é‡é—®é¢˜"""
        self.log("ğŸ”§ Running content quality fix...", "FIX")

        try:
            result = subprocess.run(
                ['python3', 'fix_seo_content.py'],
                cwd=WORK_DIR,
                capture_output=True,
                text=True,
                timeout=300
            )

            if result.returncode == 0:
                self.log("   âœ… Content fix completed successfully", "SUCCESS")
                self.fix_count += 1
                return True
            else:
                self.log(f"   âŒ Fix script failed: {result.stderr}", "ERROR")
                return False

        except subprocess.TimeoutExpired:
            self.log("   âŒ Fix script timeout", "ERROR")
            return False
        except Exception as e:
            self.log(f"   âŒ Fix error: {str(e)}", "ERROR")
            return False

    def run_seo_workflow(self):
        """è¿è¡Œå®Œæ•´SEOå·¥ä½œæµ"""
        self.log("ğŸš€ Starting SEO workflow run...", "INFO")

        try:
            # ä½¿ç”¨unbufferedæ¨¡å¼è¿è¡Œ
            process = subprocess.Popen(
                ['python3', '-u', 'run_seo_workflow.py', '--auto'],
                cwd=WORK_DIR,
                env={**os.environ, 'OPENAI_API_KEY': os.environ.get('OPENAI_API_KEY', '')},
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )

            # å®æ—¶è¾“å‡º
            for line in process.stdout:
                print(line, end='')
                sys.stdout.flush()

            process.wait(timeout=1800)  # 30åˆ†é’Ÿè¶…æ—¶

            if process.returncode == 0:
                self.log("   âœ… Workflow completed successfully", "SUCCESS")
                self.run_count += 1
                return True
            else:
                self.log(f"   âŒ Workflow failed with code {process.returncode}", "ERROR")
                return False

        except subprocess.TimeoutExpired:
            self.log("   âŒ Workflow timeout (30min)", "ERROR")
            process.kill()
            return False
        except Exception as e:
            self.log(f"   âŒ Workflow error: {str(e)}", "ERROR")
            return False

    def monitor_cycle(self):
        """å•æ¬¡ç›‘æ§å¾ªç¯"""
        self.log("="*80)
        self.log(f"ğŸ“Š Monitoring Cycle #{self.run_count + 1}")
        self.log(f"   Total runs: {self.run_count} | Total fixes: {self.fix_count}")
        self.log("="*80)

        # æ­¥éª¤1: æ£€æŸ¥å†…å®¹è´¨é‡
        issues_found = self.check_all_content()

        if issues_found:
            self.log(f"âš ï¸  Found quality issues in {len(issues_found)} files:", "WARNING")
            for item in issues_found:
                self.log(f"   ğŸ“„ {item['file']}:")
                for issue in item['issues']:
                    self.log(f"      â€¢ [{issue['severity']}] {issue['description']}")

            # æ­¥éª¤2: è‡ªåŠ¨ä¿®å¤
            self.log("\nğŸ”§ Attempting auto-fix...")
            fix_success = self.auto_fix_content()

            if fix_success:
                # é‡æ–°æ£€æŸ¥
                self.log("\nğŸ” Re-checking after fix...")
                time.sleep(2)
                issues_after_fix = self.check_all_content()

                if not issues_after_fix:
                    self.log("   âœ… All issues resolved!", "SUCCESS")
                else:
                    self.log(f"   âš ï¸  {len(issues_after_fix)} files still have issues", "WARNING")

        else:
            self.log("âœ… No quality issues detected - content is healthy!", "SUCCESS")

        # æ­¥éª¤3: æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°å†…å®¹
        try:
            if os.path.exists(PUBLISHED_CONTENT_FILE):
                with open(PUBLISHED_CONTENT_FILE, 'r') as f:
                    published = json.load(f)
                    published_count = len(published)

                self.log(f"\nğŸ“Š Current content inventory: {published_count} articles")

                # å¦‚æœå†…å®¹å°‘äº10ç¯‡ï¼Œè¿è¡Œæ–°ä¸€è½®ç”Ÿæˆ
                if published_count < 10:
                    self.log(f"   â„¹ï¸  Content count below target (10), running workflow to generate more...")
                    workflow_success = self.run_seo_workflow()

                    if workflow_success:
                        # å·¥ä½œæµæˆåŠŸåï¼Œå†æ¬¡ä¿®å¤ç¡®ä¿è´¨é‡
                        self.log("\nğŸ”§ Applying quality fix to new content...")
                        self.auto_fix_content()
                    else:
                        self.log("   âš ï¸  Workflow failed, will retry next cycle", "WARNING")
                else:
                    self.log(f"   âœ… Content inventory is healthy ({published_count}/10 target)")

        except Exception as e:
            self.log(f"   âš ï¸  Cannot check content inventory: {e}", "WARNING")

        self.last_check = datetime.now()

    def run_continuous(self):
        """æŒç»­ç›‘æ§ä¸»å¾ªç¯"""
        self.log("ğŸš€ SEO Continuous Monitoring System Started")
        self.log("="*80)
        self.log("ğŸ“‹ Configuration:")
        self.log(f"   Check interval: {CHECK_INTERVAL}s ({CHECK_INTERVAL/60:.1f} minutes)")
        self.log(f"   Content directory: {CONTENT_DIR}")
        self.log(f"   OpenAI API Key: {'âœ… Set' if os.environ.get('OPENAI_API_KEY') else 'âŒ Not set'}")
        self.log("="*80)
        self.log("\nâš ï¸  Press Ctrl+C to stop monitoring\n")

        # ç«‹å³æ‰§è¡Œç¬¬ä¸€æ¬¡æ£€æŸ¥
        try:
            self.monitor_cycle()
        except Exception as e:
            self.log(f"âŒ Cycle error: {str(e)}", "ERROR")

        # æŒç»­å¾ªç¯
        while True:
            try:
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                next_check = self.last_check.timestamp() + CHECK_INTERVAL if self.last_check else time.time()
                wait_seconds = max(0, next_check - time.time())

                if wait_seconds > 0:
                    next_time = datetime.fromtimestamp(next_check).strftime("%H:%M:%S")
                    self.log(f"\nğŸ’¤ Sleeping for {wait_seconds:.0f}s... Next check at {next_time}")
                    time.sleep(wait_seconds)

                # æ‰§è¡Œç›‘æ§å¾ªç¯
                self.monitor_cycle()

            except KeyboardInterrupt:
                self.log("\n\nğŸ›‘ Monitoring stopped by user", "WARNING")
                self.log(f"ğŸ“Š Final stats: {self.run_count} runs, {self.fix_count} fixes")
                break
            except Exception as e:
                self.log(f"âŒ Unexpected error: {str(e)}", "ERROR")
                self.log("   Will retry in 60 seconds...")
                time.sleep(60)

if __name__ == "__main__":
    monitor = SEOMonitor()
    monitor.run_continuous()
