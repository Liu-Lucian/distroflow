"""
Medium Scraper - Mediumçˆ¬è™«
é€šè¿‡Mediumçš„å…¬å¼€APIå’ŒRSSè·å–ä½œè€…ä¿¡æ¯
"""

import json
import time
import logging
import requests
from typing import List, Dict, Optional
from src.platform_scraper_base import PlatformScraperBase

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MediumScraper(PlatformScraperBase):
    """Mediumå¹³å°scraper"""

    def __init__(self, auth_file: str = "platforms_auth.json"):
        """
        åˆå§‹åŒ–Medium scraper

        Args:
            auth_file: è®¤è¯é…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(auth_file, 'r') as f:
                config = json.load(f)
            auth_config = config.get('medium', {})
        except FileNotFoundError:
            logger.warning(f"âš ï¸  Auth file {auth_file} not found, using public API")
            auth_config = {}

        super().__init__(auth_config, 'Medium')

        # Medium APIé…ç½®
        self.api_base = "https://api.medium.com/v1"
        self.public_base = "https://medium.com"

        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept': 'application/json'
        }

    def search_users(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """
        æœç´¢Mediumç”¨æˆ·ï¼ˆä½œè€…ï¼‰

        ç­–ç•¥ï¼š
        1. æœç´¢ç›¸å…³æ ‡ç­¾çš„æ–‡ç« 
        2. è·å–æ–‡ç« ä½œè€…
        3. ç­›é€‰æ´»è·ƒä½œè€…

        Args:
            keywords: æœç´¢å…³é”®è¯ï¼ˆæ ‡ç­¾ï¼‰
            limit: ç»“æœæ•°é‡

        Returns:
            ç”¨æˆ·åˆ—è¡¨
        """
        logger.info(f"ğŸ” Searching Medium for authors (limit: {limit})")

        users = []
        seen_usernames = set()

        # Mediumæ ‡ç­¾æœç´¢
        tags = keywords if keywords else ['startup', 'entrepreneurship']

        try:
            for tag in tags[:3]:  # é™åˆ¶æ ‡ç­¾æ•°é‡
                if len(users) >= limit:
                    break

                logger.info(f"   Searching tag: {tag}")

                # ä½¿ç”¨Mediumçš„å…¬å¼€feed
                feed_url = f"{self.public_base}/tag/{tag}/latest"

                response = requests.get(
                    feed_url,
                    headers=self.headers,
                    params={'format': 'json'},
                    timeout=30
                )

                if response.status_code == 200:
                    # Mediumè¿”å›çš„JSONå‰é¢æœ‰ ])}while(1);</x>
                    content = response.text
                    if content.startswith('])}while(1);</x>'):
                        content = content[16:]

                    try:
                        data = json.loads(content)
                        payload = data.get('payload', {})
                        references = payload.get('references', {})
                        users_data = references.get('User', {})

                        for user_id, user_info in users_data.items():
                            if len(users) >= limit:
                                break

                            username = user_info.get('username')
                            if username and username not in seen_usernames:
                                user = {
                                    'user_id': user_id,
                                    'username': username,
                                    'name': user_info.get('name', ''),
                                    'profile_url': f"https://medium.com/@{username}",
                                    'bio': user_info.get('bio', '')[:500],
                                    'follower_count': user_info.get('socialStats', {}).get('followerCount', 0),
                                    'platform': 'medium'
                                }

                                # åªä¿ç•™æœ‰ä¸€å®šå…³æ³¨è€…çš„ä½œè€…
                                if user['follower_count'] >= 100:
                                    users.append(user)
                                    seen_usernames.add(username)

                    except json.JSONDecodeError:
                        logger.debug(f"   Could not parse response for tag {tag}")

                time.sleep(2)  # Rate limiting

        except Exception as e:
            logger.error(f"âŒ Error searching Medium: {e}")

        logger.info(f"âœ… Found {len(users)} authors on Medium")
        return users[:limit]

    def get_user_profile(self, user_id: str) -> Dict:
        """
        è·å–Mediumç”¨æˆ·è¯¦ç»†èµ„æ–™

        Args:
            user_id: ç”¨æˆ·åæˆ–user_id

        Returns:
            ç”¨æˆ·è¯¦ç»†èµ„æ–™
        """
        logger.debug(f"ğŸ“– Fetching Medium profile: {user_id}")

        # å¦‚æœæ˜¯usernameï¼Œæ„å»ºprofile URL
        if not user_id.startswith('@'):
            user_id = f"@{user_id}"

        profile_url = f"{self.public_base}/{user_id}"

        try:
            response = requests.get(
                profile_url,
                headers=self.headers,
                params={'format': 'json'},
                timeout=30
            )

            if response.status_code == 200:
                content = response.text
                if content.startswith('])}while(1);</x>'):
                    content = content[16:]

                data = json.loads(content)
                payload = data.get('payload', {})
                user_data = payload.get('user', {})

                return {
                    'user_id': user_data.get('userId'),
                    'username': user_data.get('username'),
                    'name': user_data.get('name', ''),
                    'profile_url': profile_url,
                    'bio': user_data.get('bio', ''),
                    'follower_count': user_data.get('socialStats', {}).get('followerCount', 0),
                    'platform': 'medium'
                }

        except Exception as e:
            logger.debug(f"   Error fetching profile: {e}")

        return {
            'username': user_id,
            'profile_url': profile_url,
            'platform': 'medium',
            'status': 'not_found'
        }

    def extract_email(self, user_profile: Dict) -> Optional[str]:
        """
        ä»Mediumèµ„æ–™æå–é‚®ç®±

        Mediumä¸å…¬å¼€æ˜¾ç¤ºé‚®ç®±

        Args:
            user_profile: ç”¨æˆ·èµ„æ–™

        Returns:
            é‚®ç®±åœ°å€æˆ–None
        """
        # Mediumä¸å…¬å¼€é‚®ç®±
        return None


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    scraper = MediumScraper()

    # æµ‹è¯•æœç´¢ä½œè€…
    users = scraper.search_users(["startup", "entrepreneurship"], limit=10)

    print(f"\nâœ… Found {len(users)} authors:")
    for user in users:
        print(f"  - @{user.get('username')} ({user.get('follower_count', 0)} followers)")
        print(f"    Name: {user.get('name', 'N/A')}")
