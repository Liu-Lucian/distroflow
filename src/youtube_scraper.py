"""
YouTube Scraper - YouTubeçˆ¬è™«
ä½¿ç”¨YouTube Data API v3è·å–åˆ›ä½œè€…å’Œè¯„è®ºè€…ä¿¡æ¯
"""

import json
import time
import logging
import requests
from typing import List, Dict, Optional
from src.platform_scraper_base import PlatformScraperBase

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class YouTubeScraper(PlatformScraperBase):
    """YouTubeå¹³å°scraper"""

    def __init__(self, auth_file: str = "platforms_auth.json"):
        """
        åˆå§‹åŒ–YouTube scraper

        Args:
            auth_file: è®¤è¯é…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(auth_file, 'r') as f:
                config = json.load(f)
            auth_config = config.get('youtube', {})
        except FileNotFoundError:
            logger.warning(f"âš ï¸  Auth file {auth_file} not found")
            auth_config = {}

        super().__init__(auth_config, 'YouTube')

        # YouTube Data APIé…ç½®
        self.api_key = self.auth_config.get('api_key', '')
        self.api_base = "https://www.googleapis.com/youtube/v3"

    def search_users(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """
        æœç´¢YouTubeç”¨æˆ·ï¼ˆåˆ›ä½œè€…ï¼‰

        ç­–ç•¥ï¼ˆæ— éœ€API keyï¼‰ï¼š
        1. ä½¿ç”¨YouTubeçš„RSS feeds
        2. ä»trending videosè·å–åˆ›ä½œè€…
        3. ä»æ¨èè·å–é¢‘é“

        Args:
            keywords: æœç´¢å…³é”®è¯
            limit: ç»“æœæ•°é‡

        Returns:
            ç”¨æˆ·åˆ—è¡¨
        """
        logger.info(f"ğŸ” Searching YouTube for creators (limit: {limit}) [No API mode]")

        users = []
        seen_channel_ids = set()

        query = ' '.join(keywords) if keywords else 'startup'

        try:
            # ä½¿ç”¨æ— éœ€APIçš„æ–¹æ³•ï¼šé€šè¿‡trendingå’Œsearché¡µé¢
            if self.api_key:
                # å¦‚æœæœ‰API keyï¼Œä½¿ç”¨API
                users = self._search_with_api(query, limit)
            else:
                # å¦åˆ™ä½¿ç”¨RSSå’Œå…¬å¼€æ•°æ®
                logger.info("   Using RSS/public data (no API key)")
                users = self._search_with_rss(query, limit)

            return users

        except Exception as e:
            logger.error(f"âŒ Error searching YouTube: {e}")
            return []

    def _search_with_rss(self, query: str, limit: int) -> List[Dict]:
        """
        ä½¿ç”¨RSSå’Œå…¬å¼€æ•°æ®æœç´¢ï¼ˆæ— éœ€API keyï¼‰

        ç­–ç•¥ï¼šä½¿ç”¨YouTubeæœç´¢é¡µé¢HTMLè§£æ

        Returns:
            ç”¨æˆ·åˆ—è¡¨
        """
        users = []
        seen_channel_ids = set()

        try:
            import re

            # ä½¿ç”¨YouTubeæœç´¢é¡µé¢
            search_url = "https://www.youtube.com/results"
            params = {'search_query': query}
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'en-US,en;q=0.9'
            }

            response = requests.get(search_url, params=params, headers=headers, timeout=30)

            if response.status_code == 200:
                html = response.text

                # ä»HTMLä¸­æå–åˆå§‹æ•°æ®ï¼ˆYouTubeåœ¨é¡µé¢ä¸­åµŒå…¥JSONï¼‰
                # æŸ¥æ‰¾ var ytInitialData = {...}
                match = re.search(r'var ytInitialData = ({.+?});', html)

                if match:
                    import json
                    try:
                        data = json.loads(match.group(1))

                        # å¯¼èˆªåˆ°è§†é¢‘ç»“æœ
                        contents = data.get('contents', {}).get('twoColumnSearchResultsRenderer', {}).get('primaryContents', {}).get('sectionListRenderer', {}).get('contents', [])

                        for content in contents:
                            item_section = content.get('itemSectionRenderer', {})
                            items = item_section.get('contents', [])

                            for item in items:
                                if len(users) >= limit:
                                    break

                                # è·å–è§†é¢‘æ¸²æŸ“å™¨
                                video_renderer = item.get('videoRenderer', {})
                                if not video_renderer:
                                    continue

                                # è·å–é¢‘é“ä¿¡æ¯
                                owner_text = video_renderer.get('ownerText', {})
                                runs = owner_text.get('runs', [])
                                if not runs:
                                    continue

                                channel_name = runs[0].get('text', '')
                                # é¢‘é“IDåœ¨navigationEndpointä¸­
                                navigation = runs[0].get('navigationEndpoint', {})
                                browse_endpoint = navigation.get('browseEndpoint', {})
                                channel_id = browse_endpoint.get('browseId', '')

                                if channel_id and channel_id not in seen_channel_ids:
                                    # æ„å»ºé¢‘é“ä¿¡æ¯
                                    user = {
                                        'channel_id': channel_id,
                                        'channel_title': channel_name,
                                        'profile_url': f"https://www.youtube.com/channel/{channel_id}",
                                        'platform': 'youtube',
                                        'source': 'html_search'
                                    }

                                    users.append(user)
                                    seen_channel_ids.add(channel_id)

                                    logger.debug(f"   Found channel: {channel_name}")

                        logger.info(f"   Found {len(users)} channels from HTML search")

                    except json.JSONDecodeError as e:
                        logger.debug(f"   Error parsing YouTube data: {e}")
                else:
                    logger.info("   â„¹ï¸  YouTube HTML structure may have changed")
                    logger.info("   â„¹ï¸  Consider providing API key for better results")

        except Exception as e:
            logger.debug(f"   Error in HTML search: {e}")

        return users

    def _search_with_api(self, query: str, limit: int) -> List[Dict]:
        """
        ä½¿ç”¨APIæœç´¢ï¼ˆéœ€è¦API keyï¼‰

        Returns:
            ç”¨æˆ·åˆ—è¡¨
        """
        users = []
        seen_channel_ids = set()

        try:
            # æœç´¢è§†é¢‘
            search_url = f"{self.api_base}/search"
            params = {
                'key': self.api_key,
                'part': 'snippet',
                'q': query,
                'type': 'video',
                'maxResults': min(50, limit * 2),
                'order': 'relevance'
            }

            response = requests.get(search_url, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                videos = data.get('items', [])

                logger.info(f"   Found {len(videos)} relevant videos")

                # ä»æ¯ä¸ªè§†é¢‘æå–é¢‘é“ä¿¡æ¯
                for video in videos:
                    if len(users) >= limit:
                        break

                    snippet = video.get('snippet', {})
                    channel_id = snippet.get('channelId')
                    channel_title = snippet.get('channelTitle')

                    if channel_id and channel_id not in seen_channel_ids:
                        # è·å–é¢‘é“è¯¦ç»†ä¿¡æ¯
                        channel_data = self._get_channel_data(channel_id)
                        if channel_data:
                            channel_data['channel_title'] = channel_title
                            users.append(channel_data)
                            seen_channel_ids.add(channel_id)

                    time.sleep(0.1)  # Rate limiting

            elif response.status_code == 403:
                logger.error("âŒ YouTube API quota exceeded or invalid API key")
            else:
                logger.warning(f"   âš ï¸  Search failed: {response.status_code}")

        except Exception as e:
            logger.error(f"âŒ Error searching YouTube: {e}")

        logger.info(f"âœ… Found {len(users)} creators on YouTube")
        return users[:limit]

    def _get_channel_data(self, channel_id: str) -> Optional[Dict]:
        """
        è·å–é¢‘é“è¯¦ç»†ä¿¡æ¯

        Args:
            channel_id: YouTubeé¢‘é“ID

        Returns:
            é¢‘é“æ•°æ®å­—å…¸
        """
        try:
            channels_url = f"{self.api_base}/channels"
            params = {
                'key': self.api_key,
                'part': 'snippet,statistics',
                'id': channel_id
            }

            response = requests.get(
                channels_url,
                params=params,
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])

                if items:
                    channel = items[0]
                    snippet = channel.get('snippet', {})
                    statistics = channel.get('statistics', {})

                    # è¿‡æ»¤å°é¢‘é“ï¼ˆè‡³å°‘1000è®¢é˜…è€…ï¼‰
                    subscriber_count = int(statistics.get('subscriberCount', 0))
                    if subscriber_count < 1000:
                        return None

                    user = {
                        'channel_id': channel_id,
                        'channel_title': snippet.get('title', ''),
                        'description': snippet.get('description', '')[:500],
                        'profile_url': f"https://www.youtube.com/channel/{channel_id}",
                        'subscriber_count': subscriber_count,
                        'video_count': int(statistics.get('videoCount', 0)),
                        'view_count': int(statistics.get('viewCount', 0)),
                        'custom_url': snippet.get('customUrl', ''),
                        'platform': 'youtube'
                    }

                    return user

        except Exception as e:
            logger.debug(f"   Error getting channel {channel_id}: {e}")
            return None

    def get_user_profile(self, user_id: str) -> Dict:
        """
        è·å–YouTubeé¢‘é“è¯¦ç»†èµ„æ–™ï¼ˆä»HTMLè·å–descriptionï¼‰

        Args:
            user_id: é¢‘é“ID

        Returns:
            é¢‘é“è¯¦ç»†èµ„æ–™
        """
        logger.debug(f"ğŸ“– Fetching YouTube channel: {user_id}")

        # å¦‚æœæœ‰API keyï¼Œä½¿ç”¨APIè·å–
        if self.api_key:
            channel_data = self._get_channel_data(user_id)
            if channel_data:
                return channel_data

        # å¦åˆ™ä»HTMLé¡µé¢è·å–æè¿°
        try:
            import re
            about_url = f"https://www.youtube.com/channel/{user_id}/about"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }

            response = requests.get(about_url, headers=headers, timeout=30)

            if response.status_code == 200:
                html = response.text

                # æå–é¢‘é“æè¿°ï¼ˆåœ¨ytInitialDataä¸­ï¼‰
                match = re.search(r'var ytInitialData = ({.+?});', html)
                if match:
                    data = json.loads(match.group(1))

                    # å¯¼èˆªåˆ°description
                    try:
                        metadata = data.get('metadata', {}).get('channelMetadataRenderer', {})
                        description = metadata.get('description', '')

                        return {
                            'channel_id': user_id,
                            'channel_title': metadata.get('title', ''),
                            'description': description[:500],
                            'profile_url': f"https://www.youtube.com/channel/{user_id}",
                            'platform': 'youtube'
                        }
                    except Exception as e:
                        logger.debug(f"   Error parsing channel data: {e}")

        except Exception as e:
            logger.debug(f"   Error fetching profile HTML: {e}")

        # è¿”å›åŸºæœ¬ä¿¡æ¯
        return {
            'channel_id': user_id,
            'profile_url': f"https://www.youtube.com/channel/{user_id}",
            'platform': 'youtube',
            'status': 'not_found'
        }

    def extract_email(self, user_profile: Dict) -> Optional[str]:
        """
        ä»YouTubeé¢‘é“æå–é‚®ç®±

        YouTubeåˆ›ä½œè€…æœ‰æ—¶åœ¨é¢‘é“æè¿°æˆ–"å…³äº"é¡µé¢æ”¾ç½®é‚®ç®±

        Args:
            user_profile: é¢‘é“èµ„æ–™

        Returns:
            é‚®ç®±åœ°å€æˆ–None
        """
        description = user_profile.get('description', '')

        if not description:
            return None

        # ç®€å•çš„é‚®ç®±æå–
        import re
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        matches = re.findall(email_pattern, description)

        if matches:
            return matches[0]

        return None

    def search_video_commenters(self, video_id: str, limit: int = 20) -> List[Dict]:
        """
        è·å–è§†é¢‘çš„è¯„è®ºè€…

        Args:
            video_id: è§†é¢‘ID
            limit: æ•°é‡é™åˆ¶

        Returns:
            è¯„è®ºè€…åˆ—è¡¨
        """
        if not self.api_key:
            logger.error("âŒ YouTube API key required")
            return []

        commenters = []
        seen_channels = set()

        try:
            comments_url = f"{self.api_base}/commentThreads"
            params = {
                'key': self.api_key,
                'part': 'snippet',
                'videoId': video_id,
                'maxResults': limit,
                'order': 'relevance'
            }

            response = requests.get(
                comments_url,
                params=params,
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])

                for item in items:
                    snippet = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})
                    channel_id = snippet.get('authorChannelId', {}).get('value')
                    author_name = snippet.get('authorDisplayName')

                    if channel_id and channel_id not in seen_channels:
                        commenters.append({
                            'channel_id': channel_id,
                            'channel_title': author_name,
                            'profile_url': f"https://www.youtube.com/channel/{channel_id}",
                            'platform': 'youtube'
                        })
                        seen_channels.add(channel_id)

        except Exception as e:
            logger.debug(f"   Error getting commenters: {e}")

        return commenters


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    scraper = YouTubeScraper()

    # æµ‹è¯•æœç´¢åˆ›ä½œè€…
    users = scraper.search_users(["startup", "entrepreneur"], limit=10)

    print(f"\nâœ… Found {len(users)} creators:")
    for user in users:
        print(f"  - {user.get('channel_title')} ({user.get('subscriber_count', 0)} subscribers)")
        print(f"    URL: {user.get('profile_url')}")
