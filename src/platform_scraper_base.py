"""
å¹³å°æŠ½è±¡åŸºç±» - Platform Scraper Base
ç»Ÿä¸€çš„å¤šå¹³å°scraperæ¥å£
"""

from typing import List, Dict, Optional
from abc import ABC, abstractmethod
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PlatformScraperBase(ABC):
    """æ‰€æœ‰å¹³å°scraperçš„æŠ½è±¡åŸºç±»"""

    def __init__(self, auth_config: Dict, platform_name: str):
        """
        åˆå§‹åŒ–å¹³å°scraper

        Args:
            auth_config: è®¤è¯é…ç½®
            platform_name: å¹³å°åç§°
        """
        self.auth_config = auth_config
        self.platform_name = platform_name
        logger.info(f"ğŸ”Œ Initializing {platform_name} scraper...")

    @abstractmethod
    def search_users(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """
        æ ¹æ®å…³é”®è¯æœç´¢ç”¨æˆ·

        Args:
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            limit: è¿”å›ç”¨æˆ·æ•°é‡é™åˆ¶

        Returns:
            ç”¨æˆ·åˆ—è¡¨ï¼Œæ¯ä¸ªç”¨æˆ·æ˜¯ä¸€ä¸ªå­—å…¸
        """
        pass

    @abstractmethod
    def get_user_profile(self, user_id: str) -> Dict:
        """
        è·å–ç”¨æˆ·è¯¦ç»†èµ„æ–™

        Args:
            user_id: ç”¨æˆ·IDæˆ–ç”¨æˆ·å

        Returns:
            ç”¨æˆ·èµ„æ–™å­—å…¸
        """
        pass

    @abstractmethod
    def extract_email(self, user_profile: Dict) -> Optional[str]:
        """
        ä»ç”¨æˆ·èµ„æ–™ä¸­æå–é‚®ç®±

        Args:
            user_profile: ç”¨æˆ·èµ„æ–™

        Returns:
            é‚®ç®±åœ°å€æˆ–None
        """
        pass

    def normalize_user_data(self, raw_data: Dict) -> Dict:
        """
        å°†å¹³å°ç‰¹å®šçš„ç”¨æˆ·æ•°æ®æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼

        Args:
            raw_data: å¹³å°åŸå§‹æ•°æ®

        Returns:
            æ ‡å‡†åŒ–çš„ç”¨æˆ·æ•°æ®
        """
        return {
            'platform': self.platform_name,
            'username': raw_data.get('username', ''),
            'name': raw_data.get('name', ''),
            'bio': raw_data.get('bio', ''),
            'location': raw_data.get('location', ''),
            'website': raw_data.get('website', ''),
            'email': raw_data.get('email', ''),
            'company': raw_data.get('company', ''),
            'job_title': raw_data.get('job_title', ''),
            'followers_count': raw_data.get('followers_count', 0),
            'profile_url': raw_data.get('profile_url', ''),
            'raw_data': raw_data  # ä¿ç•™åŸå§‹æ•°æ®
        }

    def get_leads(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """
        å®Œæ•´çš„è·å–leadsæµç¨‹ï¼ˆæœç´¢ + è·å–è¯¦æƒ… + æå–é‚®ç®±ï¼‰

        Args:
            keywords: æœç´¢å…³é”®è¯
            limit: æ•°é‡é™åˆ¶

        Returns:
            æ ‡å‡†åŒ–çš„leadsåˆ—è¡¨
        """
        logger.info(f"\nğŸ” Searching {self.platform_name} for: {', '.join(keywords)}")
        logger.info(f"   Target: {limit} users")

        # Step 1: æœç´¢ç”¨æˆ·
        users = self.search_users(keywords, limit)
        logger.info(f"   âœ… Found {len(users)} users")

        # Step 2: è·å–è¯¦ç»†èµ„æ–™å’Œé‚®ç®±
        leads = []
        for i, user in enumerate(users, 1):
            try:
                # è·å–è¯¦ç»†èµ„æ–™
                profile = self.get_user_profile(user.get('id') or user.get('username'))

                # æå–é‚®ç®±
                email = self.extract_email(profile)

                # æ ‡å‡†åŒ–æ•°æ®
                normalized = self.normalize_user_data(profile)
                if email:
                    normalized['email'] = email

                leads.append(normalized)

                if i % 10 == 0:
                    logger.info(f"   Progress: {i}/{len(users)} processed")

            except Exception as e:
                logger.warning(f"   âš ï¸  Error processing user: {e}")
                continue

        logger.info(f"   âœ… Processed {len(leads)} leads")
        emails_found = sum(1 for lead in leads if lead.get('email'))
        logger.info(f"   ğŸ“§ Emails found: {emails_found}/{len(leads)} ({emails_found/len(leads)*100:.1f}%)")

        return leads
