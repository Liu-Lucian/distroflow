# Hacker News è‡ªåŠ¨å‘å¸–ç³»ç»Ÿ ğŸš€

tbh è¿™ä¸ªç³»ç»Ÿæ¯”è¯„è®ºç³»ç»Ÿæ›´ hardcoreï¼Œå› ä¸ºæ˜¯ä¸»åŠ¨å‘å¸– lol

## ç³»ç»Ÿæ¦‚è¿°

**ç›®æ ‡**: åœ¨ HN ä¸Š build in publicï¼Œé€šè¿‡çœŸè¯šçš„æŠ€æœ¯åˆ†äº«è·å¾—è‡ªç„¶æµé‡

**ç­–ç•¥**:
- æ¯æœˆ 1 æ¬¡ Show HNï¼ˆäº§å“å±•ç¤ºï¼‰
- æ¯å‘¨ 1 æ¬¡ Ask HNï¼ˆæŠ€æœ¯è®¨è®ºï¼‰
- è¯­æ°”è½»æ¾ã€çœŸè¯šï¼Œå¤šç”¨ç½‘ç»œç”¨è¯­ï¼ˆlol, tbh, ngl, imoï¼‰
- **å…³é”®**: ä¸æ¨é”€äº§å“ï¼Œåˆ†äº«æŠ€æœ¯ç»éªŒä¸ºä¸»

**AI**: Claude (Anthropic) - æ›´é€‚åˆæŠ€æœ¯ç¤¾åŒº

## å¿«é€Ÿå¼€å§‹

### 1. è®¾ç½® API Key

```bash
export ANTHROPIC_API_KEY='sk-ant-api03-vdOe-uCa...'
```

### 2. ç™»å½• HNï¼ˆä¸€æ¬¡æ€§ï¼‰

```bash
python3 hackernews_login_and_save_auth.py
```

### 3. æµ‹è¯•ç”Ÿæˆï¼ˆä¸çœŸå®å‘å¸ƒï¼‰

```bash
python3 hackernews_auto_poster.py --generate-only
```

è¿™ä¼šç”Ÿæˆå½“æœˆçš„å‘å¸–è®¡åˆ’åˆ° `schedules/hackernews_posts_2025-10.json`

### 4. å¯åŠ¨è‡ªåŠ¨å‘å¸–

```bash
python3 hackernews_auto_poster.py
```

## æ ¸å¿ƒæ–‡ä»¶

### ä¸»è¦è„šæœ¬
- `hackernews_auto_poster.py` - ä¸»è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ°¸ä¹…è¿è¡Œï¼‰
- `src/hackernews_poster.py` - HN å‘å¸–åŸºç¡€ç±»
- `hackernews_login_and_save_auth.py` - è®¤è¯è®¾ç½®

### æ•°æ®æ–‡ä»¶
- `hackernews_auth.json` - è®¤è¯ cookies
- `schedules/hackernews_posts_{month}.json` - æ¯æœˆå‘å¸–è®¡åˆ’

## å‘å¸–ç±»å‹

### Show HNï¼ˆæ¯æœˆ1æ¬¡ï¼‰

**æ ¼å¼**:
```
æ ‡é¢˜: Show HN: Real-time AI interview coach (tbh the latency was a nightmare)
URL: https://interviewasssistant.com
æ­£æ–‡: 2-4æ®µæŠ€æœ¯åˆ†äº«
```

**Claude ç”Ÿæˆçš„è¯­æ°”**:
- âœ… "ngl the hardest part was reducing first-byte latency"
- âœ… "tbh we tried everything before finding ChromaDB"
- âœ… "imo vector search is underrated for this use case"
- âŒ "Best interview tool ever! Try now!"

**ç¤ºä¾‹å†…å®¹** (Claude ä¼šç”Ÿæˆç±»ä¼¼çš„):
```
Show HN: Real-time AI interview assistant (feedback welcome)

Been working on this for 4 months, tbh the latency was the biggest pain.

Current stack:
- Azure Speech SDK (streaming ASR)
- GPT-4o for responses
- ChromaDB for vector matching

The hardest part? Getting first-byte latency from 2.7s â†’ 1.0s. We tried:
1. Dual-level caching (memory + disk)
2. Precomputing common answers
3. Vector similarity search (80% cache hit rate)

Still feels slow sometimes lol. Anyone hit sub-500ms with GPT-4?

Live demo: https://interviewasssistant.com

Would love feedback, esp on the UX!
```

### Ask HNï¼ˆæ¯å‘¨1æ¬¡ï¼‰

**æ ¼å¼**:
```
æ ‡é¢˜: Ask HN: How to reduce latency in real-time AI streaming?
æ­£æ–‡: æŠ€æœ¯é—®é¢˜ + å½“å‰æ–¹æ¡ˆ + å…·ä½“æŒ‡æ ‡ + å¯»æ±‚å»ºè®®
```

**ç¤ºä¾‹å†…å®¹** (Claude ä¼šç”Ÿæˆ):
```
Ask HN: Best approach for real-time speaker diarization?

I'm building an interview assistant and need to distinguish between
interviewer/candidate audio in real-time.

Current approach:
- Picovoice Eagle (speaker recognition)
- 48kHz audio, 512-sample frames
- ~92% accuracy but occasional misses

Main issue: when voices overlap it gets confused lol. Tried:
- Increasing frame size â†’ worse latency
- Lower threshold â†’ more false positives

ngl I'm stuck. Anyone dealt with this in production? Is there a
better engine than Eagle for this use case?

Constraints:
- Real-time (< 100ms latency)
- On-device preferred (privacy)
- English + Chinese support

Any advice appreciated!
```

## è°ƒåº¦ç³»ç»Ÿ

### æœˆåº¦è®¡åˆ’

```json
{
  "month": "2025-10",
  "posts": [
    {
      "type": "Show HN",
      "scheduled_date": "2025-10-03",
      "scheduled_time": "10:27",
      "post_data": {
        "title": "Show HN: ...",
        "url": "https://interviewasssistant.com",
        "text": "..."
      },
      "posted": false
    },
    {
      "type": "Ask HN",
      "scheduled_date": "2025-10-08",
      "scheduled_time": "14:15",
      "post_data": {
        "title": "Ask HN: ...",
        "text": "..."
      },
      "posted": false
    }
  ]
}
```

### æ—¶é—´åˆ†å¸ƒ

| å¸–å­ç±»å‹ | é¢‘ç‡ | æ—¶é—´é€‰æ‹© |
|---------|------|---------|
| Show HN | æ¯æœˆ1æ¬¡ | æœˆåˆç¬¬1-7å¤©ï¼Œä¸Šåˆ9-11ç‚¹ |
| Ask HN | æ¯å‘¨1æ¬¡ | å‘¨äºŒæˆ–å‘¨ä¸‰ï¼Œä¸Šåˆ9ç‚¹-ä¸‹åˆ4ç‚¹ |

## HN è§„èŒƒéµå¾ª

### âœ… æ¨èåšæ³•

1. **çœŸè¯šåˆ†äº«æŠ€æœ¯æŒ‘æˆ˜**
   - "ngl the hardest part was..."
   - "tbh we tried everything..."
   - Share actual numbers/metrics

2. **è½»æ¾è¯­æ°”ä½†æœ‰æ·±åº¦**
   - Use lol, tbh, ngl, imo naturally
   - But provide real technical value
   - Ask genuine questions

3. **äº§å“æåŠè‡ªç„¶**
   - Mention only when contextually relevant
   - Focus on technical challenges, not features
   - Link at end, not in title

### âŒ ç¦å¿Œè¡Œä¸º

1. **è¥é”€è¯­è¨€**
   - âŒ "Best", "Revolutionary", "Game-changing"
   - âŒ "Try now", "Sign up", "Limited offer"
   - âŒ Feature list without context

2. **ä¼ªè£…è®¨è®º**
   - âŒ Ask HN ä½†å®é™…æ˜¯äº§å“å¹¿å‘Š
   - âŒ ä¸åˆ†äº«å…·ä½“æŠ€æœ¯ç»†èŠ‚
   - âŒ ä¸å›åº”è¯„è®ºä¸­çš„æŠ€æœ¯é—®é¢˜

3. **é¢‘ç‡è¿‡é«˜**
   - âŒ æ¯å‘¨å¤šä¸ª Show HN
   - âŒ åŒä¸€ä¸»é¢˜åå¤å‘å¸–
   - âŒ ä¸å‚ä¸è¯„è®ºè®¨è®º

## Claude Prompt ç­–ç•¥

### Show HN Prompt ç‰¹ç‚¹

```python
# å…³é”®æŒ‡ä»¤
"Sound like a technical founder sharing, not a marketer pitching"
"Use casual tech founder language (lol, tbh, ngl, imo)"
"Share 1-2 technical challenges with specific metrics"
"Ask for feedback genuinely"
```

### Ask HN Prompt ç‰¹ç‚¹

```python
# å…³é”®æŒ‡ä»¤
"REAL technical question, not disguised marketing"
"Share specific numbers/metrics"
"Be humble and curious"
"DON'T pitch your product"
```

## æˆæœ¬ä¼°ç®—

```
Claude Sonnet 3.5 API:
- Show HN: ~800 tokens output â†’ $0.012
- Ask HN: ~800 tokens output â†’ $0.012

æ¯æœˆæˆæœ¬:
- 1 Show HN: $0.012
- 4 Ask HN: $0.048
Total: ~$0.06/æœˆ
```

è¶…çº§ä¾¿å®œ lol

## ç›‘æ§å’Œç»´æŠ¤

### æŸ¥çœ‹å½“æœˆè®¡åˆ’

```bash
cat schedules/hackernews_posts_2025-10.json | python3 -m json.tool
```

### æ£€æŸ¥å‘å¸ƒçŠ¶æ€

```python
python3 -c "
import json
with open('schedules/hackernews_posts_2025-10.json') as f:
    data = json.load(f)

total = len(data['posts'])
posted = sum(1 for p in data['posts'] if p['posted'])
print(f'Progress: {posted}/{total} posts published')

for p in data['posts']:
    status = 'âœ…' if p['posted'] else 'â³'
    print(f'{status} [{p[\"type\"]}] {p[\"scheduled_date\"]} - {p[\"post_data\"][\"title\"][:50]}...')
"
```

### æ‰‹åŠ¨å‘å¸ƒå•ä¸ªå¸–å­

```python
python3 -c "
import sys
sys.path.insert(0, 'src')
from hackernews_poster import HackerNewsPoster

poster = HackerNewsPoster()
poster.setup_browser(headless=False)
poster.verify_login()

post_data = {
    'title': 'Ask HN: Your question here',
    'text': 'Your content here...'
}

poster.submit_post(post_data)
input('Press Enter to close...')
poster.close_browser()
"
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: API key æ— æ•ˆ

```bash
# ç—‡çŠ¶
âŒ é”™è¯¯: æœªè®¾ç½® ANTHROPIC_API_KEY

# è§£å†³
export ANTHROPIC_API_KEY='sk-ant-api03-...'
```

### é—®é¢˜2: HN ç™»å½•å¤±æ•ˆ

```bash
# ç—‡çŠ¶
âŒ HN ç™»å½•éªŒè¯å¤±è´¥

# è§£å†³
python3 hackernews_login_and_save_auth.py  # é‡æ–°ç™»å½•
```

### é—®é¢˜3: å¸–å­è¢« flagged

**å¯èƒ½åŸå› **:
1. æ ‡é¢˜å¤ªæ¨é”€åŒ–
2. æ­£æ–‡ç¼ºå°‘æŠ€æœ¯ç»†èŠ‚
3. æ²¡æœ‰å‚ä¸è¯„è®ºè®¨è®º
4. é¢‘ç‡å¤ªé«˜

**è§£å†³**:
- Review Claude ç”Ÿæˆçš„å†…å®¹
- ç¡®ä¿æŠ€æœ¯æ·±åº¦è¶³å¤Ÿ
- ç§¯æå›å¤è¯„è®º
- é™ä½å‘å¸–é¢‘ç‡

## æœ€ä½³å®è·µ

### 1. å‘å¸–åå¿…åš

**ç«‹å³**:
- å…³æ³¨å¸–å­è¯„è®ºï¼ˆå‰30åˆ†é’Ÿæœ€å…³é”®ï¼‰
- è®¤çœŸå›å¤æŠ€æœ¯é—®é¢˜
- åˆ†äº«æ›´å¤šç»†èŠ‚å’Œä»£ç 

**ä¸è¦**:
- å‘å®Œå°±èµ°
- æ— è§†è¯„è®º
- åªå›å¤èµç¾ï¼Œä¸å›å¤è´¨ç–‘

### 2. å†…å®¹è´¨é‡æ§åˆ¶

**æ£€æŸ¥æ¸…å•**:
- [ ] æ ‡é¢˜æœ‰ç½‘ç»œç”¨è¯­ä½†ä¸å¤¸å¼ 
- [ ] æ­£æ–‡æœ‰å…·ä½“æ•°å­—/æŒ‡æ ‡
- [ ] åˆ†äº«äº†çœŸå®æŠ€æœ¯æŒ‘æˆ˜
- [ ] æ²¡æœ‰è¥é”€è¯­è¨€
- [ ] çœŸè¯šè¯·æ•™æˆ–åˆ†äº«

### 3. ç¤¾åŒºäº’åŠ¨

**æ¯å‘¨**:
- åœ¨å…¶ä»– HN å¸–å­ä¸‹è¯„è®º 2-3 æ¬¡
- åˆ†äº«ç›¸å…³æŠ€æœ¯ç»éªŒ
- å»ºç«‹ç¤¾åŒºå­˜åœ¨æ„Ÿ

## è¿›é˜¶é…ç½®

### ä¿®æ”¹å‘å¸–é¢‘ç‡

ç¼–è¾‘ `hackernews_auto_poster.py`:

```python
# æ”¹ä¸ºæ¯æœˆ 2 ä¸ª Show HN
for month_week in [0, 2]:  # ç¬¬1å‘¨å’Œç¬¬3å‘¨
    show_hn = self.generate_show_hn_post()
    # ...

# æ”¹ä¸ºæ¯å‘¨ 2 ä¸ª Ask HN
for week in range(4):
    for _ in range(2):  # æ¯å‘¨2æ¬¡
        ask_hn = self.generate_ask_hn_post()
        # ...
```

### è‡ªå®šä¹‰ Prompt é£æ ¼

```python
# æ›´è½»æ¾çš„è¯­æ°”
"Use VERY casual language (lots of lol, tbh, ngl)"

# æ›´ä¸“ä¸šçš„è¯­æ°”
"Professional but approachable tone"

# æ›´æŠ€æœ¯çš„æ·±åº¦
"Include code snippets and architecture diagrams"
```

## ä¸å…¶ä»–ç³»ç»Ÿé›†æˆ

### é…åˆè¯„è®ºç³»ç»Ÿ

```bash
# åŒæ—¶è¿è¡Œå‘å¸–å’Œè¯„è®º
tmux new-session -d -s hn-poster 'python3 hackernews_auto_poster.py'
tmux new-session -d -s hn-commenter 'python3 hackernews_auto_reply.py'

tmux ls
```

### æ•°æ®åŒæ­¥

```python
# å¯ä»¥è®©å‘å¸–ä¸»é¢˜å’Œè¯„è®ºä¸»é¢˜ä¿æŒä¸€è‡´
# ä¾‹å¦‚: Show HN åçš„ä¸€å‘¨ï¼ŒAsk HN å›´ç»•åŒä¸€æŠ€æœ¯ç‚¹
```

## å…¸å‹å‘å¸–æ¡ˆä¾‹

### Show HN - äº§å“å±•ç¤º

**å¥½çš„ä¾‹å­**:
```
Show HN: Real-time AI interview coach (latency was a nightmare lol)

URL: https://interviewasssistant.com

Been hacking on this for 4mo, ngl the biggest challenge was latency.

Tech stack:
- Azure Speech SDK (streaming ASR, 48kHz)
- GPT-4o (response generation)
- ChromaDB (vector similarity search)
- SSE (client streaming)

Key optimization:
First-byte latency: 2.7s â†’ 1.0s (60% improvement)
- Dual-level caching (memory + disk)
- Precompute common answers (80% hit rate)
- Vector matching instead of full GPT calls

Still feels slow tbh. Anyone hit sub-500ms with GPT-4?

Would love feedback on the UX! Demo linked above.
```

**ä¸ºä»€ä¹ˆå¥½**:
- âœ… è½»æ¾è¯­æ°”ï¼ˆlol, ngl, tbhï¼‰
- âœ… å…·ä½“æŠ€æœ¯æ ˆå’ŒæŒ‡æ ‡
- âœ… åˆ†äº«çœŸå®æŒ‘æˆ˜
- âœ… è¯·æ•™é—®é¢˜
- âœ… äº§å“é“¾æ¥è‡ªç„¶æ”¾ç½®

### Ask HN - æŠ€æœ¯è®¨è®º

**å¥½çš„ä¾‹å­**:
```
Ask HN: Best practices for real-time speaker diarization?

I'm building an interview assistant that needs to tell apart
interviewer/candidate voices in real-time.

Current setup:
- Picovoice Eagle (speaker recognition engine)
- 48kHz audio, 512-sample frames
- ~92% accuracy under ideal conditions

Main issue: overlapping speech. When both people talk at once,
accuracy drops to ~60%.

Tried:
- Bigger frames â†’ worse latency (unacceptable)
- Lower threshold â†’ too many false positives
- Noise gate â†’ cuts off soft speakers

ngl I'm hitting a wall here. Is this just a fundamental limit
of real-time diarization? Or am I missing something?

Anyone dealt with this in production? Alternative engines?

Constraints:
- Real-time (<100ms latency)
- Privacy (on-device preferred)
- Bilingual (English + Chinese)

Any advice would be amazing!
```

**ä¸ºä»€ä¹ˆå¥½**:
- âœ… çœŸå®æŠ€æœ¯é—®é¢˜
- âœ… è¯¦ç»†å½“å‰æ–¹æ¡ˆ
- âœ… å…·ä½“æŒ‡æ ‡å’Œçº¦æŸ
- âœ… åˆ†äº«å°è¯•è¿‡çš„æ–¹æ³•
- âœ… çœŸè¯šæ±‚åŠ©ï¼ˆnglï¼‰
- âœ… æ²¡æœ‰æ¨é”€äº§å“

## æ€»ç»“

**ç³»ç»Ÿç‰¹ç‚¹**:
- âœ… å…¨è‡ªåŠ¨ç”Ÿæˆå’Œå‘å¸ƒ
- âœ… ä½¿ç”¨ Claude (é€‚åˆæŠ€æœ¯ç¤¾åŒº)
- âœ… çœŸè¯šè¯­æ°”ï¼Œå¤šç½‘ç»œç”¨è¯­
- âœ… éµå¾ª HN è§„èŒƒ
- âœ… ä½æˆæœ¬ï¼ˆ~$0.06/æœˆï¼‰

**é€‚ç”¨åœºæ™¯**:
- Build in Public è¥é”€
- æŠ€æœ¯å“ç‰Œå»ºè®¾
- å¸å¼•æŠ€æœ¯äººæ‰
- è·å¾—æŠ€æœ¯åé¦ˆ

**å…³é”®æŒ‡æ ‡**:
- HN Karma å¢é•¿
- å¸–å­ upvote æ•°é‡
- ç½‘ç«™æµé‡å¢åŠ 
- è¯„è®ºäº’åŠ¨è´¨é‡

**ä¸‹ä¸€æ­¥**:
1. ç”Ÿæˆæµ‹è¯•è®¡åˆ’æŸ¥çœ‹å†…å®¹
2. æ‰‹åŠ¨å‘å¸ƒ1-2ä¸ªå¸–å­æµ‹è¯•åé¦ˆ
3. æ ¹æ®ç¤¾åŒºååº”è°ƒæ•´ç­–ç•¥
4. å¯åŠ¨è‡ªåŠ¨åŒ–ç³»ç»Ÿ

glhf! ğŸ‰
