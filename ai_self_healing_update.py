#!/usr/bin/env python3
"""
Product Hunt AI è‡ªæ„ˆåˆæ›´æ–°ç³»ç»Ÿ
å½“é‡åˆ°é—®é¢˜æ—¶è‡ªåŠ¨ä½¿ç”¨ AI å¯»æ±‚è§£å†³æ–¹æ¡ˆ
"""
import sys
sys.path.insert(0, 'src')

from producthunt_commenter import ProductHuntCommenter
import os
import json
import time
import base64
from datetime import datetime
from openai import OpenAI

client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))

PRODUCT_LIST_FILE = "todays_producthunt_products.json"

def ai_analyze_page_and_extract(screenshot_path: str, page_html: str) -> list:
    """ä½¿ç”¨ AI åˆ†æé¡µé¢å¹¶æå–äº§å“ä¿¡æ¯å’ŒçœŸå®é“¾æ¥"""
    print("\nğŸ¤– AI åˆ†æé¡µé¢...")

    # è¯»å–æˆªå›¾
    with open(screenshot_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')

    # ä» HTML ä¸­æå–æ‰€æœ‰å¯èƒ½çš„äº§å“é“¾æ¥
    import re
    all_links = re.findall(r'/posts/([a-zA-Z0-9-]+)', page_html)
    unique_slugs = list(set([slug for slug in all_links if slug not in ['new', 'all']]))[:30]

    prompt = f"""ä½ æ˜¯ Product Hunt ä¸“å®¶ã€‚åˆ†æè¿™å¼  Product Hunt é¦–é¡µæˆªå›¾ã€‚

**ä»»åŠ¡**:
1. è¯†åˆ«é¡µé¢ä¸Šçš„æ‰€æœ‰äº§å“ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
2. å¯¹äºæ¯ä¸ªäº§å“ï¼Œæå–ï¼š
   - äº§å“åç§°ï¼ˆå‡†ç¡®è¯†åˆ«ï¼‰
   - äº§å“æè¿°/æ ‡è¯­
   - äº§å“ç±»åˆ«

**é¡µé¢ä¸Šæ‰¾åˆ°çš„ URL slugs**:
{', '.join(unique_slugs[:15])}

**è¦æ±‚**:
1. è¯†åˆ« 5-10 ä¸ªäº§å“
2. å¯¹äºæ¯ä¸ªäº§å“ï¼Œä»ä¸Šé¢çš„ slugs åˆ—è¡¨ä¸­é€‰æ‹©**æœ€åŒ¹é…çš„ slug**
3. å¦‚æœæ— æ³•ç¡®å®šåŒ¹é…ï¼Œæ ¹æ®äº§å“åç§°ç”Ÿæˆåˆç†çš„ slugï¼ˆå°å†™ï¼Œç”¨è¿å­—ç¬¦ï¼‰
4. **æŒ‰ç…§é¡µé¢æ˜¾ç¤ºé¡ºåºæ’åˆ—**

**è¾“å‡ºæ ¼å¼**ï¼ˆçº¯ JSONï¼Œæ— å…¶ä»–æ–‡å­—ï¼‰:
```json
[
  {{
    "name": "äº§å“åç§°",
    "slug": "æœ€åŒ¹é…çš„-slug-æˆ–-ç”Ÿæˆçš„-slug",
    "tagline": "äº§å“æè¿°",
    "category": "ç±»åˆ«",
    "confidence": "high/medium/low"
  }}
]
```

**åŒ¹é…è§„åˆ™**:
- high: äº§å“ååœ¨ slugs ä¸­æ‰¾åˆ°ç²¾ç¡®æˆ–éå¸¸æ¥è¿‘çš„åŒ¹é…
- medium: æœ‰å¯èƒ½çš„åŒ¹é…ä½†ä¸ç¡®å®š
- low: åªèƒ½çŒœæµ‹

å¼€å§‹åˆ†æï¼š"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.3
        )

        ai_output = response.choices[0].message.content.strip()
        print(f"ğŸ“‹ AI åˆ†æç»“æœ:\n{ai_output[:500]}...\n")

        # æå– JSON
        if "```json" in ai_output:
            ai_output = ai_output.split("```json")[1].split("```")[0].strip()
        elif "```" in ai_output:
            ai_output = ai_output.split("```")[1].split("```")[0].strip()

        products_data = json.loads(ai_output)

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        products = []
        for item in products_data[:10]:
            slug = item.get('slug', item.get('name', '').lower().replace(' ', '-').replace('.', ''))
            confidence = item.get('confidence', 'medium')

            products.append({
                'url': f"https://www.producthunt.com/posts/{slug}",
                'name': item.get('name', 'Product'),
                'tagline': item.get('tagline', 'Product from Product Hunt'),
                'category': item.get('category', 'Various'),
                'description': item.get('tagline', 'Product from Product Hunt'),
                'confidence': confidence
            })

        print(f"âœ… AI æå– {len(products)} ä¸ªäº§å“")
        for p in products[:3]:
            print(f"   â€¢ {p['name']} ({p['confidence']}) - {p['url']}")

        return products

    except Exception as e:
        print(f"âŒ AI åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def verify_product_url(url: str, commenter: ProductHuntCommenter) -> bool:
    """éªŒè¯äº§å“ URL æ˜¯å¦æœ‰æ•ˆ"""
    try:
        commenter.page.goto(url, timeout=30000, wait_until='domcontentloaded')
        time.sleep(2)

        # æ£€æŸ¥æ˜¯å¦æ˜¯ 404
        page_text = commenter.page.text_content('body').lower()
        if 'lost this page' in page_text or '404' in page_text or 'not found' in page_text:
            return False

        return True
    except:
        return False

def ai_fix_broken_url(product: dict, screenshot_path: str, page_html: str) -> str:
    """ä½¿ç”¨ AI ä¿®å¤æŸåçš„ URL"""
    print(f"\nğŸ”§ AI è‡ªåŠ¨ä¿®å¤: {product['name']}")

    # ä» HTML æå–å€™é€‰ slugs
    import re
    all_slugs = re.findall(r'/posts/([a-zA-Z0-9-]+)', page_html)
    unique_slugs = list(set([s for s in all_slugs if s not in ['new', 'all']]))

    # è¯»å–æˆªå›¾
    with open(screenshot_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')

    prompt = f"""ä½ æ˜¯ Product Hunt URL ä¿®å¤ä¸“å®¶ã€‚

**é—®é¢˜**: äº§å“ "{product['name']}" çš„ URL æ— æ•ˆ: {product['url']}

**é¡µé¢å¯ç”¨çš„ URL slugs**:
{', '.join(unique_slugs[:20])}

**ä»»åŠ¡**:
1. åˆ†ææˆªå›¾ï¼Œæ‰¾åˆ°äº§å“ "{product['name']}"
2. ä»ä¸Šé¢çš„ slugs ä¸­é€‰æ‹©æœ€åŒ¹é…çš„
3. å¦‚æœæ‰¾ä¸åˆ°ï¼Œç”Ÿæˆæœ€å¯èƒ½çš„ slug

**è¾“å‡ºæ ¼å¼**ï¼ˆåªè¾“å‡º slugï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰:
```
æ­£ç¡®çš„-slug
```

å¼€å§‹åˆ†æï¼š"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/png;base64,{image_data}"}
                        }
                    ]
                }
            ],
            max_tokens=100,
            temperature=0.3
        )

        fixed_slug = response.choices[0].message.content.strip().strip('`').strip()
        fixed_url = f"https://www.producthunt.com/posts/{fixed_slug}"

        print(f"   AI å»ºè®®: {fixed_url}")
        return fixed_url

    except Exception as e:
        print(f"   âŒ AI ä¿®å¤å¤±è´¥: {str(e)}")
        return None

def main():
    print("=" * 80)
    print("ğŸ¤– Product Hunt AI è‡ªæ„ˆåˆæ›´æ–°ç³»ç»Ÿ")
    print("=" * 80)

    if not os.environ.get('OPENAI_API_KEY'):
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY")
        return 1

    commenter = ProductHuntCommenter()

    try:
        # æ­¥éª¤ 1: è®¿é—®é¦–é¡µ
        print("\nğŸŒ è®¿é—® Product Hunt é¦–é¡µ...")
        commenter.setup_browser(headless=True)

        if not commenter.verify_login():
            print("âŒ ç™»å½•å¤±è´¥")
            return 1

        commenter.page.goto("https://www.producthunt.com", timeout=60000)
        print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
        time.sleep(10)

        # æ»šåŠ¨åŠ è½½
        commenter.page.evaluate("window.scrollTo(0, 1500)")
        time.sleep(3)
        commenter.page.evaluate("window.scrollTo(0, 0)")
        time.sleep(2)

        # æˆªå›¾
        screenshot_path = "ph_homepage_screenshot.png"
        commenter.page.screenshot(path=screenshot_path, full_page=False)
        print(f"ğŸ“¸ æˆªå›¾ä¿å­˜: {screenshot_path}")

        # è·å–é¡µé¢ HTML
        page_html = commenter.page.content()

        commenter.close_browser()

        # æ­¥éª¤ 2: AI åˆ†ææå–äº§å“
        products = ai_analyze_page_and_extract(screenshot_path, page_html)

        if not products:
            print("âŒ AI æœªèƒ½æå–äº§å“")
            return 1

        # æ­¥éª¤ 3: éªŒè¯ URLï¼ˆé‡æ–°æ‰“å¼€æµè§ˆå™¨ï¼‰
        print("\nğŸ” éªŒè¯äº§å“ URL...")
        commenter.setup_browser(headless=True)
        commenter.verify_login()

        verified_products = []
        for i, product in enumerate(products, 1):
            print(f"\néªŒè¯ {i}/{len(products)}: {product['name']}")
            print(f"   URL: {product['url']}")

            if verify_product_url(product['url'], commenter):
                print(f"   âœ… URL æœ‰æ•ˆ")
                verified_products.append(product)
            else:
                print(f"   âŒ URL æ— æ•ˆï¼Œå°è¯• AI ä¿®å¤...")

                # AI è‡ªåŠ¨ä¿®å¤
                fixed_url = ai_fix_broken_url(product, screenshot_path, page_html)

                if fixed_url and verify_product_url(fixed_url, commenter):
                    print(f"   âœ… ä¿®å¤æˆåŠŸ: {fixed_url}")
                    product['url'] = fixed_url
                    product['ai_fixed'] = True
                    verified_products.append(product)
                else:
                    print(f"   âš ï¸  æ— æ³•ä¿®å¤ï¼Œè·³è¿‡æ­¤äº§å“")

            # é™åˆ¶ 5 ä¸ªäº§å“
            if len(verified_products) >= 5:
                break

        commenter.close_browser()

        if not verified_products:
            print("\nâŒ æ²¡æœ‰æœ‰æ•ˆçš„äº§å“")
            return 1

        # æ­¥éª¤ 4: ä¿å­˜
        data = {
            "date": datetime.now().strftime('%Y-%m-%d'),
            "source": "AI Self-Healing System",
            "products": verified_products,
            "updated_at": datetime.now().isoformat()
        }

        with open(PRODUCT_LIST_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… æˆåŠŸä¿å­˜ {len(verified_products)} ä¸ªéªŒè¯çš„äº§å“")
        print("\nğŸ“‹ äº§å“åˆ—è¡¨:")
        for i, p in enumerate(verified_products, 1):
            fixed_mark = " [AIä¿®å¤]" if p.get('ai_fixed') else ""
            print(f"   {i}. {p['name']}{fixed_mark}")
            print(f"      {p['url']}")

        print("\n" + "=" * 80)
        print("âœ… AI è‡ªæ„ˆåˆæ›´æ–°å®Œæˆï¼")
        print("=" * 80)

        return 0

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        try:
            commenter.close_browser()
        except:
            pass

if __name__ == "__main__":
    sys.exit(main())
