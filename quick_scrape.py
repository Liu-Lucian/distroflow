#!/usr/bin/env python3
"""
å¿«é€Ÿçˆ¬å–è„šæœ¬ - è‡ªåŠ¨ç™»å½•ç‰ˆæœ¬
Quick scrape with auto-login
"""

import sys
from src.twitter_scraper import TwitterWebScraper
import pandas as pd

if len(sys.argv) < 2:
    print("ç”¨æ³•: python quick_scrape.py <ç”¨æˆ·å> [æ•°é‡]")
    print("ç¤ºä¾‹: python quick_scrape.py elonmusk 50")
    sys.exit(1)

target_user = sys.argv[1]
count = int(sys.argv[2]) if len(sys.argv) > 2 else 50

print("=" * 60)
print("Twitter å¿«é€Ÿçˆ¬è™« (è‡ªåŠ¨ç™»å½•)")
print("=" * 60)
print(f"ç›®æ ‡: @{target_user}")
print(f"æ•°é‡: {count} ç²‰ä¸")
print("=" * 60)
print()

# åˆ›å»ºçˆ¬è™«ï¼ˆè‡ªåŠ¨ç™»å½•ï¼‰
scraper = TwitterWebScraper(headless=False, auto_login=True)

try:
    print("ğŸ” å¼€å§‹çˆ¬å–ç²‰ä¸...")
    followers = scraper.get_followers(
        username=target_user,
        max_followers=count,
        extract_emails=True
    )
    
    if followers:
        print()
        print("=" * 60)
        print(f"âœ“ æˆåŠŸçˆ¬å– {len(followers)} ä¸ªç²‰ä¸")
        print("=" * 60)
        
        # ç»Ÿè®¡é‚®ç®±
        emails = [f for f in followers if f.get('email')]
        print(f"ğŸ“§ æ‰¾åˆ°é‚®ç®±: {len(emails)} ({len(emails)/len(followers)*100:.1f}%)")
        print()
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæœ‰é‚®ç®±çš„
        if emails:
            print("æœ‰é‚®ç®±çš„ç²‰ä¸æ ·ä¾‹:")
            for i, f in enumerate(emails[:5], 1):
                print(f"{i}. @{f['username']} - {f['email']}")
            print()
        
        # å¯¼å‡º
        df = pd.DataFrame(followers)
        filename = f'exports/twitter_{target_user}_{count}.csv'
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ“ æ•°æ®å·²å¯¼å‡º: {filename}")
        print()
        print("ğŸ‰ å®Œæˆ!")
    else:
        print("âŒ æœªè·å–åˆ°æ•°æ®")

except KeyboardInterrupt:
    print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
finally:
    scraper.close()
