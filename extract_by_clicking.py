#!/usr/bin/env python3
"""
é€šè¿‡ç‚¹å‡»äº§å“å…ƒç´ æ¥æå–çœŸå® URL
æœ€å¯é çš„æ–¹æ³•ï¼šç›´æ¥ä¸é¡µé¢äº¤äº’
"""
import sys
sys.path.insert(0, 'src')

from producthunt_commenter import ProductHuntCommenter
import os
import json
import time
from datetime import datetime

PRODUCT_LIST_FILE = "todays_producthunt_products.json"

def extract_products_by_clicking(commenter: ProductHuntCommenter) -> list:
    """é€šè¿‡ç‚¹å‡»äº§å“å¡ç‰‡æ¥æå– URL"""
    print("\nğŸ” é€šè¿‡ç‚¹å‡»æå–äº§å“...")

    products = []

    try:
        # ç­‰å¾…é¡µé¢åŠ è½½
        print("   â³ ç­‰å¾…é¡µé¢åŠ è½½...")
        time.sleep(10)

        # æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»çš„äº§å“å…ƒç´ 
        js_code = """
        () => {
            // æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½æ˜¯äº§å“çš„å…ƒç´ 
            // Product Hunt é€šå¸¸ä½¿ç”¨ article æˆ–ç‰¹å®šçš„ div
            const candidates = [
                ...document.querySelectorAll('article'),
                ...document.querySelectorAll('[data-test*="post"]'),
                ...document.querySelectorAll('div[class*="Post"]'),
                ...document.querySelectorAll('div[role="article"]')
            ];

            const products = [];
            const seen = new Set();

            for (const elem of candidates) {
                // æŸ¥æ‰¾å†…éƒ¨çš„é“¾æ¥
                const link = elem.querySelector('a[href*="/posts/"]');
                if (!link) continue;

                const href = link.getAttribute('href');
                if (!href || href.includes('/posts/new')) continue;

                // å°è¯•è·å–äº§å“åç§°
                const nameElem = elem.querySelector('h2, h3, strong, [class*="name"], [class*="title"]');
                const name = nameElem ? nameElem.textContent.trim() : '';

                if (name && !seen.has(href)) {
                    seen.add(href);
                    products.push({
                        name: name,
                        href: href,
                        elem_id: products.length
                    });

                    // ç»™å…ƒç´ æ·»åŠ  ID ä»¥ä¾¿åç»­ç‚¹å‡»
                    elem.setAttribute('data-product-id', products.length.toString());
                }

                if (products.length >= 10) break;
            }

            return products;
        }
        """

        initial_products = commenter.page.evaluate(js_code)
        print(f"   âœ… æ‰¾åˆ° {len(initial_products)} ä¸ªäº§å“å…ƒç´ ")

        if not initial_products:
            print("   âš ï¸  æœªæ‰¾åˆ°äº§å“å…ƒç´ ï¼Œå°è¯•ç®€å•é“¾æ¥æå–...")

            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥æŸ¥æ‰¾é“¾æ¥å¹¶è®¿é—®
            js_code_simple = """
            () => {
                const links = document.querySelectorAll('a[href*="/posts/"]');
                const products = [];

                for (const link of links) {
                    const href = link.getAttribute('href');
                    if (href && !href.includes('/posts/new') && !href.includes('/posts/all')) {
                        const text = link.textContent.trim();
                        if (text.length > 2 && text.length < 100) {
                            products.push({
                                name: text,
                                href: href
                            });

                            if (products.length >= 10) break;
                        }
                    }
                }

                return products;
            }
            """

            initial_products = commenter.page.evaluate(js_code_simple)
            print(f"   å¤‡ç”¨æ–¹æ¡ˆæ‰¾åˆ° {len(initial_products)} ä¸ªé“¾æ¥")

        # å¯¹æ¯ä¸ªäº§å“ï¼Œè®¿é—®å…¶é¡µé¢è·å–å®Œæ•´ä¿¡æ¯
        for i, prod_info in enumerate(initial_products[:10], 1):
            try:
                name = prod_info.get('name', '')
                href = prod_info.get('href', '')

                if not href:
                    continue

                print(f"\n   ğŸ“¦ äº§å“ {i}/{len(initial_products)}: {name[:40]}...")

                # æ„é€ å®Œæ•´ URL
                if href.startswith('/'):
                    full_url = f"https://www.producthunt.com{href}"
                else:
                    full_url = href

                # è®¿é—®äº§å“é¡µé¢
                commenter.page.goto(full_url, timeout=30000)
                time.sleep(3)

                # ä»æµè§ˆå™¨åœ°å€æ è·å–å®é™… URLï¼ˆå¯èƒ½æœ‰é‡å®šå‘ï¼‰
                actual_url = commenter.page.url.split('?')[0].split('#')[0]

                # æ£€æŸ¥æ˜¯å¦æ˜¯ 404
                page_text = commenter.page.text_content('body').lower()
                is_404 = 'lost this page' in page_text or '404' in page_text

                if is_404:
                    print(f"      âŒ 404 - è·³è¿‡")
                    continue

                # å°è¯•ä»é¡µé¢æå–æ›´å¤šä¿¡æ¯
                page_info_js = """
                () => {
                    return {
                        title: document.title,
                        tagline: (document.querySelector('[class*="tagline"]') ||
                                 document.querySelector('meta[name="description"]'))?.textContent ||
                                 document.querySelector('meta[name="description"]')?.getAttribute('content') || ''
                    };
                }
                """

                page_info = commenter.page.evaluate(page_info_js)

                # æå– slug
                slug_match = actual_url.split('/posts/')[1] if '/posts/' in actual_url else ''

                if slug_match:
                    products.append({
                        'url': actual_url,
                        'name': page_info.get('title', name).split('|')[0].split('-')[0].strip()[:50],
                        'tagline': page_info.get('tagline', f'{name} - Product from Product Hunt')[:200],
                        'category': 'Various',
                        'description': page_info.get('tagline', '')[:200],
                        'votes': 0
                    })

                    print(f"      âœ… URL: {actual_url}")

                # è¿”å›é¦–é¡µç»§ç»­
                commenter.page.goto("https://www.producthunt.com", timeout=30000)
                time.sleep(2)

            except Exception as e:
                print(f"      âŒ é”™è¯¯: {e}")
                # å°è¯•è¿”å›é¦–é¡µ
                try:
                    commenter.page.goto("https://www.producthunt.com", timeout=30000)
                    time.sleep(2)
                except:
                    pass
                continue

        print(f"\n   âœ… æˆåŠŸæå– {len(products)} ä¸ªäº§å“")
        return products

    except Exception as e:
        print(f"   âŒ æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def main():
    print("=" * 80)
    print("ğŸ” Product Hunt ç‚¹å‡»æå–ï¼ˆæœ€å¯é æ–¹æ³•ï¼‰")
    print("=" * 80)

    commenter = ProductHuntCommenter()

    try:
        print("\nğŸŒ è®¿é—® Product Hunt é¦–é¡µ...")
        commenter.setup_browser(headless=True)

        if not commenter.verify_login():
            print("âŒ ç™»å½•å¤±è´¥")
            return 1

        commenter.page.goto("https://www.producthunt.com", timeout=60000)

        # æå–äº§å“
        products = extract_products_by_clicking(commenter)

        commenter.close_browser()

        if not products:
            print("\nâŒ æœªèƒ½æå–äº§å“")
            return 1

        # ä¿å­˜
        data = {
            "date": datetime.now().strftime('%Y-%m-%d'),
            "source": "Click and Extract Method",
            "products": products,
            "updated_at": datetime.now().isoformat()
        }

        with open(PRODUCT_LIST_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"\n" + "=" * 80)
        print(f"âœ… æˆåŠŸä¿å­˜ {len(products)} ä¸ªäº§å“")
        print("=" * 80)
        print("\nğŸ“‹ äº§å“åˆ—è¡¨:")
        for i, p in enumerate(products, 1):
            print(f"   {i}. {p['name']}")
            print(f"      {p['tagline'][:70]}...")
            print(f"      {p['url']}")
            print()

        return 0

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        try:
            commenter.close_browser()
        except:
            pass

if __name__ == "__main__":
    sys.exit(main())
