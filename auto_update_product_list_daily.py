#!/usr/bin/env python3
"""
Product Hunt äº§å“åˆ—è¡¨ - æ¯æ—¥è‡ªåŠ¨ AI æ›´æ–°
ä½¿ç”¨ GPT-4o Vision è‡ªåŠ¨è¯†åˆ«é¦–é¡µäº§å“å¹¶æ›´æ–°åˆ—è¡¨
"""
import sys
sys.path.insert(0, 'src')

from producthunt_commenter import ProductHuntCommenter
import os
import json
import time
import base64
from datetime import datetime
from openai import OpenAI

client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))

PRODUCT_LIST_FILE = "todays_producthunt_products.json"

def capture_producthunt_homepage() -> tuple:
    """æˆªå›¾ Product Hunt é¦–é¡µå¹¶æå–çœŸå®äº§å“é“¾æ¥"""
    print("ğŸŒ è®¿é—® Product Hunt é¦–é¡µ...")

    commenter = ProductHuntCommenter()
    commenter.setup_browser(headless=True)

    if not commenter.verify_login():
        print("âŒ ç™»å½•å¤±è´¥")
        commenter.close_browser()
        return None, []

    # è®¿é—®é¦–é¡µ
    commenter.page.goto("https://www.producthunt.com", timeout=60000)
    print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
    time.sleep(10)

    # æ»šåŠ¨ä»¥åŠ è½½æ›´å¤šäº§å“
    commenter.page.evaluate("window.scrollTo(0, 1500)")
    time.sleep(3)
    commenter.page.evaluate("window.scrollTo(0, 0)")
    time.sleep(2)

    # æå–çœŸå®çš„äº§å“é“¾æ¥
    print("ğŸ”— æå–äº§å“é“¾æ¥...")
    real_links = []
    try:
        all_links = commenter.page.query_selector_all('a')
        for link in all_links:
            href = link.get_attribute('href')
            if href and '/posts/' in href:
                # è·³è¿‡ç‰¹æ®Šé“¾æ¥
                if any(skip in href for skip in ['/posts/new', '/posts/all', '/posts?', '/posts#']):
                    continue

                # æ„é€ å®Œæ•´ URL
                if href.startswith('/'):
                    full_url = f"https://www.producthunt.com{href}"
                else:
                    full_url = href

                # æ¸…ç† URL
                full_url = full_url.split('?')[0].split('#')[0]

                # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„äº§å“ URL
                if full_url.endswith('/posts/') or full_url.endswith('/posts'):
                    continue

                if full_url not in real_links:
                    real_links.append(full_url)

        print(f"   æ‰¾åˆ° {len(real_links)} ä¸ªçœŸå®äº§å“é“¾æ¥")
    except Exception as e:
        print(f"   âš ï¸  æå–é“¾æ¥å¤±è´¥: {str(e)}")

    # æˆªå›¾
    screenshot_path = "ph_homepage_screenshot.png"
    commenter.page.screenshot(path=screenshot_path, full_page=False)
    print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")

    commenter.close_browser()
    return screenshot_path, real_links

def extract_products_with_ai(screenshot_path: str, real_links: list) -> list:
    """ä½¿ç”¨ AI Vision æå–äº§å“ä¿¡æ¯"""
    print("\nğŸ¤– ä½¿ç”¨ AI Vision åˆ†ææˆªå›¾...")

    # è¯»å–æˆªå›¾å¹¶è½¬æ¢ä¸º base64
    with open(screenshot_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')

    prompt = """åˆ†æè¿™å¼  Product Hunt é¦–é¡µæˆªå›¾ï¼Œæå–æ‰€æœ‰å¯è§çš„äº§å“ä¿¡æ¯ã€‚

**ä»»åŠ¡**:
1. è¯†åˆ«é¡µé¢ä¸Šæ‰€æœ‰ä»Šæ—¥äº§å“ï¼ˆä»ä¸Šåˆ°ä¸‹é¡ºåºï¼‰
2. å¯¹äºæ¯ä¸ªäº§å“ï¼Œæå–ï¼š
   - äº§å“åç§°
   - äº§å“ç®€ä»‹/æ ‡è¯­ï¼ˆtaglineï¼‰
   - äº§å“ç±»åˆ«/æ ‡ç­¾ï¼ˆå¦‚æœå¯è§ï¼‰
3. é€‰æ‹© 5-10 ä¸ªæœ€ç›¸å…³çš„äº§å“ï¼ˆä¼˜å…ˆ AI Tools, Productivity, Developer Toolsï¼‰
4. **æŒ‰ç…§é¡µé¢ä¸Šçš„æ˜¾ç¤ºé¡ºåºæ’åˆ—**

**è¾“å‡ºæ ¼å¼** (ä¸¥æ ¼çš„ JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–æ–‡æœ¬):
```json
[
  {
    "name": "äº§å“åç§°",
    "tagline": "äº§å“ç®€ä»‹",
    "category": "äº§å“ç±»åˆ«"
  }
]
```

**æ³¨æ„**:
- åªè¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—
- ä¸éœ€è¦ç”Ÿæˆ slug æˆ– URLï¼Œæˆ‘ä»¬ä¼šè‡ªåŠ¨åŒ¹é…
- å¦‚æœçœ‹ä¸æ¸…æŸäº›ä¿¡æ¯ï¼Œç”¨åˆç†çš„å€¼
- è‡³å°‘æå– 5 ä¸ªäº§å“ï¼Œæœ€å¤š 10 ä¸ª
- **é‡è¦**: æŒ‰ç…§é¡µé¢ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºæ’åˆ—äº§å“

å¼€å§‹åˆ†æï¼š"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # ä½¿ç”¨ Vision æ¨¡å‹
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1500,
            temperature=0.3
        )

        ai_output = response.choices[0].message.content.strip()
        print(f"\nğŸ“‹ AI è¯†åˆ«ç»“æœ:\n{ai_output}\n")

        # æå– JSONï¼ˆå¯èƒ½è¢«åŒ…è£¹åœ¨ ```json ``` ä¸­ï¼‰
        if "```json" in ai_output:
            ai_output = ai_output.split("```json")[1].split("```")[0].strip()
        elif "```" in ai_output:
            ai_output = ai_output.split("```")[1].split("```")[0].strip()

        products_data = json.loads(ai_output)

        # å¦‚æœæ²¡æœ‰çœŸå®é“¾æ¥ï¼Œä»äº§å“åç”Ÿæˆ slug
        if not real_links or len(real_links) == 0:
            print("   âš ï¸  ä½¿ç”¨ AI è¯†åˆ«çš„äº§å“åç”Ÿæˆ URL")
            products = []
            for item in products_data[:10]:
                name = item.get('name', 'Product')
                slug = name.lower().replace(' ', '-').replace('.', '')
                products.append({
                    'url': f"https://www.producthunt.com/posts/{slug}",
                    'name': name,
                    'tagline': item.get('tagline', 'Product from Product Hunt'),
                    'category': item.get('category', 'Various'),
                    'description': item.get('tagline', 'Product from Product Hunt')
                })
            print(f"âœ… æˆåŠŸæå– {len(products)} ä¸ªäº§å“ï¼ˆAI ç”Ÿæˆ URLï¼‰")
            return products

        # ä½¿ç”¨çœŸå®é“¾æ¥åŒ¹é… AI è¯†åˆ«çš„äº§å“
        products = []
        num_products = min(len(products_data), len(real_links), 10)

        for i in range(num_products):
            item = products_data[i] if i < len(products_data) else {}
            url = real_links[i] if i < len(real_links) else f"https://www.producthunt.com/posts/product-{i}"

            products.append({
                'url': url,  # ä½¿ç”¨çœŸå®é“¾æ¥
                'name': item.get('name', 'Product'),
                'tagline': item.get('tagline', 'Product from Product Hunt'),
                'category': item.get('category', 'Various'),
                'description': item.get('tagline', 'Product from Product Hunt')
            })

        print(f"âœ… æˆåŠŸæå– {len(products)} ä¸ªäº§å“ï¼ˆä½¿ç”¨çœŸå®é“¾æ¥ï¼‰")
        return products

    except json.JSONDecodeError as e:
        print(f"âŒ AI è¿”å›çš„ JSON æ ¼å¼é”™è¯¯: {e}")
        print(f"åŸå§‹è¾“å‡º: {ai_output}")
        # å¦‚æœ AI å¤±è´¥ä½†æœ‰çœŸå®é“¾æ¥ï¼Œç›´æ¥ä½¿ç”¨çœŸå®é“¾æ¥
        if real_links:
            print("âš ï¸  ä½¿ç”¨çœŸå®é“¾æ¥ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ...")
            return create_products_from_links(real_links[:10])
        return []
    except Exception as e:
        print(f"âŒ AI åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        # å¦‚æœ AI å¤±è´¥ä½†æœ‰çœŸå®é“¾æ¥ï¼Œç›´æ¥ä½¿ç”¨çœŸå®é“¾æ¥
        if real_links:
            print("âš ï¸  ä½¿ç”¨çœŸå®é“¾æ¥ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ...")
            return create_products_from_links(real_links[:10])
        return []

def create_products_from_links(links: list) -> list:
    """ä»é“¾æ¥åˆ›å»ºäº§å“åˆ—è¡¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    products = []
    for url in links[:10]:
        try:
            # ä» URL æå–äº§å“å
            slug = url.split('/posts/')[-1].strip('/')
            name = slug.replace('-', ' ').title()

            products.append({
                'url': url,
                'name': name,
                'tagline': f'{name} - Product from Product Hunt',
                'category': 'Various',
                'description': f'Product discovered from Product Hunt'
            })
        except:
            continue

    return products

def save_product_list(products: list):
    """ä¿å­˜äº§å“åˆ—è¡¨åˆ°æ–‡ä»¶"""
    data = {
        "date": datetime.now().strftime('%Y-%m-%d'),
        "source": "Auto-updated via AI Vision",
        "products": products,
        "updated_at": datetime.now().isoformat()
    }

    with open(PRODUCT_LIST_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… äº§å“åˆ—è¡¨å·²ä¿å­˜åˆ°: {PRODUCT_LIST_FILE}")
    print(f"   åŒ…å« {len(products)} ä¸ªäº§å“")

def main():
    print("=" * 80)
    print("ğŸ¤– Product Hunt äº§å“åˆ—è¡¨ - æ¯æ—¥è‡ªåŠ¨ AI æ›´æ–°")
    print("=" * 80)

    # æ£€æŸ¥ API key
    if not os.environ.get('OPENAI_API_KEY'):
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY")
        print("   export OPENAI_API_KEY='sk-proj-...'")
        return 1

    # æ­¥éª¤ 1: æˆªå›¾é¦–é¡µå¹¶æå–çœŸå®é“¾æ¥
    screenshot_path, real_links = capture_producthunt_homepage()
    if not screenshot_path:
        print("âŒ æˆªå›¾å¤±è´¥")
        return 1

    if not real_links:
        print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°äº§å“é“¾æ¥ï¼Œå°†ä¾èµ– AI çŒœæµ‹")

    # æ­¥éª¤ 2: AI æå–äº§å“ä¿¡æ¯å¹¶åŒ¹é…çœŸå®é“¾æ¥
    products = extract_products_with_ai(screenshot_path, real_links)
    if not products:
        print("âŒ AI æœªèƒ½æå–åˆ°äº§å“")
        return 1

    # æ­¥éª¤ 3: ä¿å­˜åˆ—è¡¨
    save_product_list(products)

    # æ˜¾ç¤ºäº§å“é¢„è§ˆ
    print("\nğŸ“‹ äº§å“åˆ—è¡¨é¢„è§ˆ:")
    for i, p in enumerate(products, 1):
        print(f"   {i}. {p['name']}")
        print(f"      {p['tagline']}")
        print(f"      {p['url']}")

    print("\n" + "=" * 80)
    print("âœ… è‡ªåŠ¨æ›´æ–°å®Œæˆï¼")
    print(f"   å¯ä»¥ç›´æ¥è¿è¡Œ: python3 auto_producthunt_forever.py")
    print("=" * 80)

    return 0

if __name__ == "__main__":
    sys.exit(main())
