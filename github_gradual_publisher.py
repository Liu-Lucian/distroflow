#!/usr/bin/env python3
"""
GitHub æŒ¤ç‰™è†å¼å‘å¸ƒç³»ç»Ÿ
======================

æ™ºèƒ½åœ°å°†é¡¹ç›®é€æ­¥æäº¤åˆ° GitHubï¼Œå¢åŠ  activity å’Œæ›å…‰åº¦ã€‚

ç­–ç•¥ï¼š
- æŒ‰æ¨¡å—æ‹†åˆ†ä»£ç ï¼ˆ30+ ä¸ª commitsï¼‰
- æ¯å¤© 1-3 ä¸ª commitsï¼ˆéšæœºåŒ–é¿å…è§„å¾‹ï¼‰
- æœ‰æ„ä¹‰çš„ commit messages
- æŒ‰é€»è¾‘é¡ºåºå‘å¸ƒï¼ˆåŸºç¡€è®¾æ–½ â†’ æ ¸å¿ƒåŠŸèƒ½ â†’ é«˜çº§åŠŸèƒ½ï¼‰

è¿è¡Œï¼š
    python3 github_gradual_publisher.py --init     # åˆå§‹åŒ–ä»“åº“
    python3 github_gradual_publisher.py --once     # æäº¤ä¸€æ¬¡
    python3 github_gradual_publisher.py --forever  # æ°¸ä¹…è¿è¡Œ
"""

import os
import sys
import json
import time
import random
import logging
import subprocess
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('github_publisher.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ==================== é…ç½® ====================

CONFIG = {
    # GitHub ä»“åº“é…ç½®
    'repo_url': 'https://github.com/q1q1-spefic/interview_assistant.git',
    'repo_name': 'interview_assistant',
    'branch': 'main',

    # æºä»£ç è·¯å¾„
    'source_dir': '/Users/l.u.c/my-app/interview_assistant',

    # å‘å¸ƒé¢‘ç‡
    'commits_per_day': {
        'min': 1,
        'max': 3
    },

    # æäº¤æ—¶é—´çª—å£ï¼ˆé¿å…åŠå¤œæäº¤ï¼‰
    'commit_time_windows': [
        (9, 12),    # ä¸Šåˆ 9:00-11:59
        (14, 18),   # ä¸‹åˆ 2:00-17:59
        (20, 24)    # æ™šä¸Š 8:00-23:59
    ],

    # æ£€æŸ¥é—´éš”ï¼ˆå°æ—¶ï¼‰
    'check_interval_hours': 6
}

# ==================== æ¨¡å—å®šä¹‰ ====================

# æŒ‰é€»è¾‘é¡ºåºå®šä¹‰è¦å‘å¸ƒçš„æ¨¡å—
# æ¯ä¸ªæ¨¡å—åŒ…å«ï¼šæ–‡ä»¶åˆ—è¡¨ã€commit æ¶ˆæ¯ã€æè¿°
MODULES = [
    # ===== ç¬¬ 1 é˜¶æ®µï¼šé¡¹ç›®åŸºç¡€è®¾æ–½ =====
    {
        'name': 'project-setup',
        'files': ['requirements.txt', 'requirements_minimal.txt', '.env.example', 'setup.sh', 'start.sh'],
        'message': 'ğŸ‰ Initial commit: Project setup and dependencies',
        'description': 'Core project configuration and setup scripts'
    },
    {
        'name': 'readme',
        'files': ['README.md', 'CLAUDE.md', 'LICENSE'],
        'message': 'ğŸ“š Add comprehensive documentation',
        'description': 'Project documentation and license'
    },
    {
        'name': 'config',
        'files': ['config.py', 'project.config.json'],
        'message': 'âš™ï¸ Add system configuration module',
        'description': 'Centralized configuration management'
    },

    # ===== ç¬¬ 2 é˜¶æ®µï¼šæ ¸å¿ƒæ•°æ®åº“å’Œå·¥å…· =====
    {
        'name': 'database-setup',
        'files': ['database_migration.py', 'user_data_migration.py'],
        'message': 'ğŸ—„ï¸ Add database migration system',
        'description': 'Database schema management and migration tools'
    },
    {
        'name': 'user-auth',
        'files': ['user_auth.py', 'admin_auth.py', 'user_id_helper.py'],
        'message': 'ğŸ” Implement user authentication system',
        'description': 'User login, registration, and session management'
    },
    {
        'name': 'email-service',
        'files': ['email_service.py', 'email_verification.py'],
        'message': 'ğŸ“§ Add email verification system',
        'description': 'Email sending and verification functionality'
    },

    # ===== ç¬¬ 3 é˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½ - ç®€å†å¤„ç† =====
    {
        'name': 'resume-parser',
        'files': ['enhanced_resume_parser.py', 'advanced_resume_analyzer.py'],
        'message': 'ğŸ“„ Implement advanced resume parsing (GPT-4 powered)',
        'description': 'AI-powered resume parsing and analysis'
    },
    {
        'name': 'resume-optimizer',
        'files': ['resume_optimizer.py', 'resume_version_manager.py'],
        'message': 'âœ¨ Add resume optimization and version control',
        'description': 'Resume improvement suggestions and version management'
    },
    {
        'name': 'resume-service',
        'files': ['resume_analysis_service.py', 'version_comparator.py'],
        'message': 'ğŸ” Add resume analysis service layer',
        'description': 'Resume analysis API and version comparison'
    },

    # ===== ç¬¬ 4 é˜¶æ®µï¼šJD å¤„ç†å’Œå®ä½“æå– =====
    {
        'name': 'jd-analyzer',
        'files': ['advanced_jd_analyzer.py', 'advanced_entity_extractor.py'],
        'message': 'ğŸ¯ Implement job description analyzer',
        'description': 'AI-powered JD parsing and entity extraction'
    },
    {
        'name': 'tech-enhancer',
        'files': ['tech_question_enhancer.py', 'interview_template_matcher.py'],
        'message': 'ğŸ’¡ Add technical question enhancement',
        'description': 'Technical interview question generation and matching'
    },

    # ===== ç¬¬ 5 é˜¶æ®µï¼šé¢è¯•é¢˜æ¨¡æ¿ç³»ç»Ÿ =====
    {
        'name': 'template-database',
        'files': ['template_deduplicator.py', 'intelligent_deduplicator.py'],
        'message': 'ğŸ§¹ Implement template deduplication system',
        'description': 'Smart template deduplication using embeddings'
    },
    {
        'name': 'template-quality',
        'files': ['template_quality_enhancer.py', 'template_operation_logger.py'],
        'message': 'â­ Add template quality enhancement',
        'description': 'Template quality scoring and operation logging'
    },
    {
        'name': 'template-optimization',
        'files': ['enhanced_star_optimizer.py', 'optimized_deduplicator.py'],
        'message': 'ğŸš€ Optimize template STAR framework',
        'description': 'STAR/PREP framework optimization for interview answers'
    },

    # ===== ç¬¬ 6 é˜¶æ®µï¼šè¯­éŸ³è¯†åˆ«å’Œå¤„ç† =====
    {
        'name': 'voice-assistant',
        'files': ['voice_interview_assistant.py', 'streaming_api.py'],
        'message': 'ğŸ¤ Implement voice interview assistant (Azure Speech)',
        'description': 'Real-time voice transcription and streaming'
    },
    {
        'name': 'speaker-recognition',
        'files': ['eagle_speaker_recognition.py', 'simple_speaker_detection.py'],
        'message': 'ğŸ‘¤ Add speaker recognition (Picovoice Eagle)',
        'description': 'Speaker diarization for interview recordings'
    },
    {
        'name': 'speaker-enrollment',
        'files': ['speaker_enrollment_manager.py', 'eagle_frame_processor.py'],
        'message': 'ğŸ”Š Implement speaker enrollment system',
        'description': 'Voice profile creation and management'
    },

    # ===== ç¬¬ 7 é˜¶æ®µï¼šæ¨¡æ‹Ÿé¢è¯•ç³»ç»Ÿ =====
    {
        'name': 'mock-interview-basic',
        'files': ['mock_interview_manager.py'],
        'message': 'ğŸ­ Add basic mock interview functionality',
        'description': 'Basic mock interview session management'
    },
    {
        'name': 'mock-interview-advanced',
        'files': ['advanced_mock_interview_manager.py', 'advanced_mock_interview_session.py'],
        'message': 'ğŸš€ Implement advanced mock interview system',
        'description': 'Advanced mock interviews with AI feedback'
    },
    {
        'name': 'realtime-mock',
        'files': ['realtime_mock_interview_engine.py', 'realtime_mock_routes.py', 'websocket_interview_handler.py'],
        'message': 'âš¡ Add real-time mock interview engine',
        'description': 'WebSocket-based real-time mock interviews'
    },

    # ===== ç¬¬ 8 é˜¶æ®µï¼šè®°å¿†å’Œå›¾è°±ç³»ç»Ÿ =====
    {
        'name': 'memory-basic',
        'files': ['memory_graph_manager.py', 'memory_tier_manager.py'],
        'message': 'ğŸ§  Implement memory graph system',
        'description': 'Graph-based memory management for user context'
    },
    {
        'name': 'memory-advanced',
        'files': ['enhanced_memory_graph_manager.py', 'openai_memory_manager.py'],
        'message': 'ğŸ”® Add enhanced memory management (OpenAI powered)',
        'description': 'AI-powered memory conflict resolution'
    },
    {
        'name': 'memory-optimization',
        'files': ['memory_importance_adjuster.py', 'memory_merger.py'],
        'message': 'ğŸ“Š Optimize memory importance and merging',
        'description': 'Memory importance scoring and intelligent merging'
    },

    # ===== ç¬¬ 9 é˜¶æ®µï¼šå‘é‡æœç´¢å’Œä¼˜åŒ– =====
    {
        'name': 'vector-search',
        'files': ['vector_similarity_detector.py', 'optimized_graph_engine.py'],
        'message': 'ğŸ” Implement vector similarity search',
        'description': 'ChromaDB-based semantic search for templates'
    },
    {
        'name': 'identity-resolver',
        'files': ['identity_resolver.py', 'integration_guide.py'],
        'message': 'ğŸ†” Add identity resolution system',
        'description': 'User identity matching and integration'
    },

    # ===== ç¬¬ 10 é˜¶æ®µï¼šæ”¯ä»˜å’Œæ¨èç³»ç»Ÿ =====
    {
        'name': 'payment-system',
        'files': ['payment_system.py', 'payment_system_migration.py', 'run_payment_migration.py'],
        'message': 'ğŸ’³ Implement payment system',
        'description': 'Premium feature payment and subscription'
    },
    {
        'name': 'referral-system',
        'files': ['referral_tracker.py', 'referral_codes.py'],
        'message': 'ğŸ Add referral tracking system',
        'description': 'Referral code generation and reward tracking'
    },
    {
        'name': 'blogger-management',
        'files': ['blogger_management.py', 'smart_display_filter.py'],
        'message': 'ğŸ“¢ Implement blogger management',
        'description': 'Content creator management and filtering'
    },

    # ===== ç¬¬ 11 é˜¶æ®µï¼šåˆ†æå’Œå®‰å…¨ =====
    {
        'name': 'user-analytics',
        'files': ['user_analytics.py', 'task_manager.py'],
        'message': 'ğŸ“ˆ Add user analytics and task management',
        'description': 'User behavior tracking and async task queue'
    },
    {
        'name': 'device-fingerprint',
        'files': ['device_fingerprint.py'],
        'message': 'ğŸ”’ Implement device fingerprinting',
        'description': 'Fraud prevention and device tracking'
    },
    {
        'name': 'video-analysis',
        'files': ['video_behavior_analyzer.py'],
        'message': 'ğŸ“¹ Add video behavior analysis',
        'description': 'Interview video recording and behavior analysis'
    },

    # ===== ç¬¬ 12 é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ– =====
    {
        'name': 'performance',
        'files': ['performance_optimizer.py', 'optimized_fixed.py'],
        'message': 'âš¡ Add performance optimization modules',
        'description': 'System performance monitoring and optimization'
    },
    {
        'name': 'feedback-handler',
        'files': ['feedback_handler.py', 'global_manager.py'],
        'message': 'ğŸ’¬ Implement feedback collection system',
        'description': 'User feedback and global state management'
    },

    # ===== ç¬¬ 13 é˜¶æ®µï¼šå‰ç«¯æ¨¡æ¿ =====
    {
        'name': 'templates-core',
        'files': ['templates/index.html', 'templates/login.html', 'templates/register.html', 'templates/base.html'],
        'message': 'ğŸ¨ Add core frontend templates',
        'description': 'Main UI templates (login, register, home)'
    },
    {
        'name': 'templates-resume',
        'files': ['templates/upload_resume.html', 'templates/resume_analysis.html', 'templates/optimize_resume.html'],
        'message': 'ğŸ“ Add resume management templates',
        'description': 'Resume upload, analysis, and optimization UI'
    },
    {
        'name': 'templates-interview',
        'files': ['templates/interview_templates.html', 'templates/mock_interview.html', 'templates/realtime_mock.html'],
        'message': 'ğŸ­ Add interview templates UI',
        'description': 'Mock interview and template management UI'
    },
    {
        'name': 'templates-advanced',
        'files': ['templates/speaker_enrollment.html', 'templates/payment.html', 'templates/referral.html'],
        'message': 'ğŸ”§ Add advanced feature templates',
        'description': 'Speaker enrollment, payment, and referral UI'
    },
    {
        'name': 'static-assets',
        'files': ['static/css/style.css', 'static/js/main.js', 'robots.txt'],
        'message': 'ğŸ¨ Add static assets and styles',
        'description': 'CSS, JavaScript, and static resources'
    },

    # ===== ç¬¬ 14 é˜¶æ®µï¼šä¸»åº”ç”¨ =====
    {
        'name': 'main-application',
        'files': ['interview_assistant_system.py'],
        'message': 'ğŸ—ï¸ Add main Flask application (11k+ lines)',
        'description': 'Core Flask app integrating all modules'
    },

    # ===== ç¬¬ 15 é˜¶æ®µï¼šæµ‹è¯•å’Œæ–‡æ¡£ =====
    {
        'name': 'tests',
        'files': ['test_eagle.py', 'test_speaker_recognition.py', 'resume_analysis_test.py'],
        'message': 'ğŸ§ª Add comprehensive test suite',
        'description': 'Unit tests for speaker recognition and resume analysis'
    },
    {
        'name': 'integration-docs',
        'files': ['REALTIME_MOCK_INTERVIEW_INTEGRATION.md', 'MarketingBrief.md'],
        'message': 'ğŸ“– Add integration and marketing documentation',
        'description': 'Technical integration guides and marketing materials'
    },

    # ===== ç¬¬ 16 é˜¶æ®µï¼šå›½é™…åŒ– =====
    {
        'name': 'i18n',
        'files': ['babel.cfg', 'extract_useful_translations.py'],
        'message': 'ğŸŒ Add internationalization support',
        'description': 'Bilingual support (English/Chinese)'
    },
]

# ==================== GitHub å‘å¸ƒå™¨ ====================

class GitHubGradualPublisher:
    """æŒ¤ç‰™è†å¼ GitHub å‘å¸ƒå™¨"""

    def __init__(self):
        self.source_dir = CONFIG['source_dir']
        self.repo_url = CONFIG['repo_url']
        self.repo_name = CONFIG['repo_name']
        self.state_file = 'github_publisher_state.json'
        self.state = self.load_state()

    def load_state(self) -> Dict:
        """åŠ è½½å‘å¸ƒçŠ¶æ€"""
        try:
            with open(self.state_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                'initialized': False,
                'current_module_index': 0,
                'total_commits': 0,
                'commits_today': 0,
                'last_commit_date': None,
                'completed_modules': []
            }

    def save_state(self):
        """ä¿å­˜å‘å¸ƒçŠ¶æ€"""
        with open(self.state_file, 'w') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def run_command(self, cmd: str, cwd: str = None) -> tuple:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                shell=True,
                cwd=cwd or self.repo_name,
                capture_output=True,
                text=True,
                check=True
            )
            return True, result.stdout
        except subprocess.CalledProcessError as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {cmd}")
            logger.error(f"é”™è¯¯: {e.stderr}")
            return False, e.stderr

    def init_repository(self):
        """åˆå§‹åŒ– Git ä»“åº“"""
        logger.info("=" * 80)
        logger.info("ğŸ“¦ åˆå§‹åŒ– Git ä»“åº“")
        logger.info("=" * 80)

        # æ£€æŸ¥æºç›®å½•
        if not os.path.exists(self.source_dir):
            logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {self.source_dir}")
            return False

        # åˆ›å»ºä»“åº“ç›®å½•
        if os.path.exists(self.repo_name):
            logger.warning(f"ä»“åº“ç›®å½•å·²å­˜åœ¨: {self.repo_name}")
            choice = input("æ˜¯å¦åˆ é™¤å¹¶é‡æ–°åˆå§‹åŒ–ï¼Ÿ(y/N): ").strip().lower()
            if choice == 'y':
                import shutil
                shutil.rmtree(self.repo_name)
            else:
                return False

        # åˆå§‹åŒ– Git
        logger.info("åˆå§‹åŒ– Git ä»“åº“...")
        os.makedirs(self.repo_name, exist_ok=True)

        success, _ = self.run_command("git init")
        if not success:
            return False

        # è®¾ç½®é»˜è®¤åˆ†æ”¯ä¸º main
        logger.info("è®¾ç½®é»˜è®¤åˆ†æ”¯ä¸º main...")
        self.run_command("git config init.defaultBranch main")

        # å¦‚æœå½“å‰æ˜¯ masterï¼Œé‡å‘½åä¸º main
        success, output = self.run_command("git branch --show-current")
        if success and output.strip() == "master":
            logger.info("é‡å‘½å master åˆ†æ”¯ä¸º main...")
            self.run_command("git branch -m master main")

        # é…ç½® Git
        self.run_command('git config user.name "q1q1-spefic"')
        self.run_command('git config user.email "your-email@example.com"')

        # æ·»åŠ è¿œç¨‹ä»“åº“
        logger.info(f"æ·»åŠ è¿œç¨‹ä»“åº“: {self.repo_url}")
        self.run_command(f'git remote add origin {self.repo_url}')

        # åˆ›å»º .gitignore
        self.create_gitignore()

        # åˆ›å»º README.md
        self.create_readme()

        # æ ‡è®°ä¸ºå·²åˆå§‹åŒ–
        self.state['initialized'] = True
        self.save_state()

        logger.info("âœ… ä»“åº“åˆå§‹åŒ–å®Œæˆ")
        return True

    def create_gitignore(self):
        """åˆ›å»º .gitignore"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/

# Environment Variables
.env
.env.local

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Database
*.db
*.sqlite
*.sqlite3

# Logs
*.log
logs/
debug.log

# OS
.DS_Store
Thumbs.db

# User Uploads
uploads/
data/

# Backup files
*.backup
*.bak
backup_*/

# Test files
test_audio.wav
test_*.txt

# Temporary files
temp_*.py
*.tmp

# Campaign tracking
campaign_tracking.db
"""
        with open(f'{self.repo_name}/.gitignore', 'w') as f:
            f.write(gitignore_content)

    def create_readme(self):
        """åˆ›å»º README.md"""
        readme_content = """# ğŸ¯ AI Interview Assistant (å³ç­”ä¾  / HireMeAI)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-orange.svg)](https://openai.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> ğŸš€ **Real-time AI-powered interview preparation system** with voice recognition, mock interviews, and personalized question generation.

---

## âœ¨ Key Features

### ğŸ“„ Resume Intelligence
- **AI Resume Parser** - GPT-4 powered resume analysis (PDF/DOCX/TXT)
- **Smart Optimization** - AI-driven resume improvement suggestions
- **Version Control** - Track and compare resume versions
- **Entity Extraction** - Extract skills, experience, and education

### ğŸ¯ Job Matching
- **JD Analysis** - Automatic job description parsing from URLs or text
- **Skill Gap Detection** - Identify missing skills and experience
- **Match Scoring** - Resume-JD compatibility scoring

### ğŸ’¡ Interview Preparation
- **Personalized Questions** - AI-generated questions based on your resume and JD
- **STAR Framework** - Behavioral questions with STAR/PREP structure
- **Template Library** - ChromaDB-powered semantic search for 1000+ questions
- **Difficulty Levels** - Questions categorized by difficulty

### ğŸ¤ Voice & Mock Interviews
- **Real-time Mock Interviews** - Practice with AI interviewer
- **Voice Recognition** - Azure Speech Services integration
- **Speaker Diarization** - Picovoice Eagle speaker recognition
- **AI Feedback** - Instant analysis and improvement suggestions
- **WebSocket Streaming** - Low-latency real-time conversations

### ğŸ§  Memory & Context
- **Graph-based Memory** - Persistent user context across sessions
- **Vector Search** - Semantic similarity for template matching
- **Intelligent Deduplication** - Smart template and question merging

### ğŸ’³ Premium Features
- **Payment System** - Subscription and one-time payment support
- **Referral Program** - Reward system for user referrals
- **Device Fingerprinting** - Fraud prevention

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API Key
- Azure Speech Services Key (optional, for voice features)
- Picovoice Access Key (optional, for speaker recognition)

### Installation

```bash
# Clone the repository
git clone https://github.com/q1q1-spefic/interview_assistant.git
cd interview_assistant

# Run setup script
chmod +x setup.sh
./setup.sh

# Configure environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Running the Application

```bash
# Start the server
python interview_assistant_system.py

# Or use the start script
./start.sh

# Access at http://localhost:5001
```

---

## ğŸ—ï¸ Architecture

```
interview_assistant/
â”œâ”€â”€ interview_assistant_system.py  # Main Flask application (11k+ lines)
â”œâ”€â”€ config.py                      # System configuration
â”‚
â”œâ”€â”€ Resume Processing
â”‚   â”œâ”€â”€ enhanced_resume_parser.py
â”‚   â”œâ”€â”€ resume_optimizer.py
â”‚   â””â”€â”€ resume_analysis_service.py
â”‚
â”œâ”€â”€ JD & Entity Extraction
â”‚   â”œâ”€â”€ advanced_jd_analyzer.py
â”‚   â””â”€â”€ advanced_entity_extractor.py
â”‚
â”œâ”€â”€ Interview Templates
â”‚   â”œâ”€â”€ template_deduplicator.py
â”‚   â”œâ”€â”€ enhanced_star_optimizer.py
â”‚   â””â”€â”€ interview_template_matcher.py
â”‚
â”œâ”€â”€ Voice & Mock Interviews
â”‚   â”œâ”€â”€ voice_interview_assistant.py
â”‚   â”œâ”€â”€ eagle_speaker_recognition.py
â”‚   â”œâ”€â”€ advanced_mock_interview_manager.py
â”‚   â””â”€â”€ realtime_mock_interview_engine.py
â”‚
â”œâ”€â”€ Memory & Vector Search
â”‚   â”œâ”€â”€ memory_graph_manager.py
â”‚   â”œâ”€â”€ enhanced_memory_graph_manager.py
â”‚   â””â”€â”€ vector_similarity_detector.py
â”‚
â”œâ”€â”€ User Management
â”‚   â”œâ”€â”€ user_auth.py
â”‚   â”œâ”€â”€ payment_system.py
â”‚   â””â”€â”€ referral_tracker.py
â”‚
â””â”€â”€ templates/                     # Jinja2 HTML templates
```

---

## ğŸ’» Tech Stack

- **Backend**: Flask, SQLite, ChromaDB
- **AI**: OpenAI GPT-4, GPT-4o-mini
- **Voice**: Azure Speech Services, Picovoice Eagle
- **Vector DB**: ChromaDB (embeddings search)
- **Frontend**: Jinja2, vanilla JavaScript
- **Real-time**: WebSocket, Server-Sent Events (SSE)

---

## ğŸ“Š Performance Metrics

- **Resume Parsing**: ~5s (PDF/DOCX â†’ Structured JSON)
- **Question Generation**: ~3s (50 personalized questions)
- **First-byte Latency**: ~1.0s (real-time mock interview)
- **Speaker Recognition**: 95% accuracy (Picovoice Eagle)
- **Template Search**: <100ms (ChromaDB vector similarity)

---

## ğŸ”§ Configuration

Edit `.env` with your API keys:

```bash
OPENAI_API_KEY=your_openai_key
AZURE_SPEECH_KEY=your_azure_key
AZURE_SPEECH_REGION=eastus
PICOVOICE_ACCESS_KEY=your_picovoice_key  # Optional
```

See `config.py` for advanced configuration options.

---

## ğŸ“– Documentation

- [Technical Documentation](CLAUDE.md)
- [Real-time Mock Interview Integration](REALTIME_MOCK_INTERVIEW_INTEGRATION.md)
- [Marketing Brief](MarketingBrief.md)

---

## ğŸ§ª Testing

```bash
# Run tests
python test_speaker_recognition.py
python resume_analysis_test.py
python test_eagle.py
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 API
- Microsoft Azure for Speech Services
- Picovoice for Eagle Speaker Recognition
- ChromaDB for vector similarity search

---

## ğŸ“ Contact

- Website: [interviewasssistant.com](https://interviewasssistant.com)
- GitHub: [@q1q1-spefic](https://github.com/q1q1-spefic)

---

**â­ Star this repo if you find it helpful!**
"""
        with open(f'{self.repo_name}/README.md', 'w') as f:
            f.write(readme_content)

    def should_commit_now(self) -> bool:
        """åˆ¤æ–­ç°åœ¨æ˜¯å¦åº”è¯¥æäº¤"""

        # é‡ç½®æ¯æ—¥è®¡æ•°å™¨
        today_str = datetime.now().strftime('%Y-%m-%d')
        last_commit_date = self.state.get('last_commit_date', '')

        # åªæœ‰å½“ä¸Šæ¬¡æäº¤æ—¥æœŸæ˜¯ä¸åŒçš„ä¸€å¤©æ—¶æ‰é‡ç½®
        if last_commit_date and last_commit_date != today_str:
            logger.info(f"ğŸ“… æ–°çš„ä¸€å¤©ï¼ˆä¸Šæ¬¡: {last_commit_date}ï¼Œä»Šå¤©: {today_str}ï¼‰ï¼Œé‡ç½®æäº¤è®¡æ•°å™¨")
            self.state['commits_today'] = 0
            self.save_state()

        # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ä»Šæ—¥é™é¢
        max_commits = CONFIG['commits_per_day']['max']
        if self.state['commits_today'] >= max_commits:
            logger.info(f"â¸ï¸  ä»Šæ—¥æäº¤å·²è¾¾ä¸Šé™ ({self.state['commits_today']}/{max_commits})")
            return False

        # æ£€æŸ¥æ˜¯å¦åœ¨æäº¤æ—¶é—´çª—å£å†…
        current_hour = datetime.now().hour
        in_time_window = any(
            start <= current_hour < end
            for start, end in CONFIG['commit_time_windows']
        )

        if not in_time_window:
            logger.info(f"â¸ï¸  å½“å‰æ—¶é—´ ({current_hour}:00) ä¸åœ¨æäº¤çª—å£å†…")
            return False

        # ç¡®ä¿è¾¾åˆ°æœ€å°‘æäº¤æ•°
        min_commits = CONFIG['commits_per_day']['min']
        if self.state['commits_today'] < min_commits:
            logger.info(f"âœ… ä»Šæ—¥æäº¤æœªè¾¾æœ€ä½è¦æ±‚ ({self.state['commits_today']}/{min_commits})")
            return True

        # éšæœºå†³å®š (40% æ¦‚ç‡)
        if random.random() < 0.4:
            logger.info("âœ… éšæœºå†³å®šæäº¤")
            return True
        else:
            logger.info("â¸ï¸  éšæœºå†³å®šæš‚ä¸æäº¤")
            return False

    def copy_files(self, module: Dict) -> bool:
        """å¤åˆ¶æ¨¡å—æ–‡ä»¶åˆ°ä»“åº“"""
        logger.info(f"ğŸ“‚ å¤åˆ¶æ–‡ä»¶: {module['name']}")

        copied_count = 0
        for file_path in module['files']:
            src = os.path.join(self.source_dir, file_path)
            dst = os.path.join(self.repo_name, file_path)

            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(os.path.dirname(dst), exist_ok=True)

            # å¤åˆ¶æ–‡ä»¶
            if os.path.isfile(src):
                import shutil
                shutil.copy2(src, dst)
                copied_count += 1
                logger.info(f"  âœ“ {file_path}")
            elif os.path.isdir(src):
                # å¦‚æœæ˜¯ç›®å½•ï¼Œå¤åˆ¶æ•´ä¸ªç›®å½•
                import shutil
                if os.path.exists(dst):
                    shutil.rmtree(dst)
                shutil.copytree(src, dst)
                copied_count += 1
                logger.info(f"  âœ“ {file_path}/ (directory)")
            else:
                logger.warning(f"  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        logger.info(f"âœ… å¤åˆ¶äº† {copied_count} ä¸ªæ–‡ä»¶/ç›®å½•")
        return copied_count > 0

    def commit_module(self, module: Dict) -> bool:
        """æäº¤ä¸€ä¸ªæ¨¡å—"""
        logger.info("\n" + "=" * 80)
        logger.info(f"ğŸ“¦ æäº¤æ¨¡å—: {module['name']}")
        logger.info(f"   {module['description']}")
        logger.info("=" * 80)

        # å¤åˆ¶æ–‡ä»¶
        if not self.copy_files(module):
            logger.error("æ²¡æœ‰æ–‡ä»¶è¢«å¤åˆ¶ï¼Œè·³è¿‡æäº¤")
            return False

        # Git add
        logger.info("ğŸ“ æ·»åŠ æ–‡ä»¶åˆ° Git...")
        success, _ = self.run_command('git add .')
        if not success:
            return False

        # Git commit
        logger.info(f"ğŸ’¾ æäº¤: {module['message']}")
        commit_message = f"{module['message']}\n\n{module['description']}"
        success, _ = self.run_command(f'git commit -m "{commit_message}"')
        if not success:
            logger.warning("æ²¡æœ‰å˜æ›´éœ€è¦æäº¤")
            return False

        # ç¡®ä¿åˆ†æ”¯å­˜åœ¨ä¸”åç§°æ­£ç¡®
        success, current_branch = self.run_command("git branch --show-current")
        if not success or not current_branch.strip():
            logger.error("æ— æ³•è·å–å½“å‰åˆ†æ”¯")
            return False

        current_branch = current_branch.strip()
        target_branch = CONFIG["branch"]

        # å¦‚æœå½“å‰åˆ†æ”¯ä¸æ˜¯ç›®æ ‡åˆ†æ”¯ï¼Œé‡å‘½å
        if current_branch != target_branch:
            logger.info(f"é‡å‘½ååˆ†æ”¯ {current_branch} -> {target_branch}")
            self.run_command(f"git branch -m {current_branch} {target_branch}")
            current_branch = target_branch

        # Git push
        logger.info(f"ğŸš€ æ¨é€åˆ° GitHub (åˆ†æ”¯: {current_branch})...")

        # é¦–æ¬¡æ¨é€ä½¿ç”¨ -u è®¾ç½®ä¸Šæ¸¸
        success, output = self.run_command(f'git push -u origin {current_branch}')

        if not success:
            logger.error("æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¿œç¨‹ä»“åº“æƒé™")
            logger.error(f"è¯¦ç»†é”™è¯¯: {output}")
            return False

        # æ›´æ–°çŠ¶æ€
        self.state['current_module_index'] += 1
        self.state['total_commits'] += 1
        self.state['commits_today'] += 1
        self.state['last_commit_date'] = datetime.now().isoformat()
        self.state['completed_modules'].append(module['name'])
        self.save_state()

        logger.info(f"âœ… æäº¤æˆåŠŸï¼æ€»è®¡: {self.state['total_commits']} commits")
        return True

    def setup_git_auth(self):
        """è®¾ç½® Git è®¤è¯"""

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¯å¢ƒå˜é‡ä¸­çš„ token
        github_token = os.getenv('GITHUB_TOKEN')

        if github_token:
            logger.info("ğŸ” ä½¿ç”¨ç¯å¢ƒå˜é‡ GITHUB_TOKEN é…ç½®è®¤è¯...")

            # æ›´æ–°è¿œç¨‹ URL åŒ…å« token
            success, _ = self.run_command(f'git remote set-url origin https://{github_token}@github.com/q1q1-spefic/interview_assistant.git')

            if success:
                logger.info("âœ… è®¤è¯é…ç½®æˆåŠŸ")
                return True
            else:
                logger.error("âŒ è®¤è¯é…ç½®å¤±è´¥")
                return False

        # æ£€æŸ¥å½“å‰çš„è¿œç¨‹ URL
        success, output = self.run_command("git remote get-url origin")

        if success:
            url = output.strip()

            # å¦‚æœæ˜¯ HTTPS ä¸”åŒ…å« tokenï¼Œè¯´æ˜å·²é…ç½®
            if 'https://' in url and '@github.com' in url:
                logger.info("âœ… è¿œç¨‹ URL å·²åŒ…å«è®¤è¯ä¿¡æ¯")
                return True

            # å¦‚æœæ˜¯ SSHï¼Œæ£€æŸ¥ SSH å¯†é’¥
            if 'git@github.com' in url:
                logger.info("ğŸ”‘ ä½¿ç”¨ SSH è®¤è¯")
                # æµ‹è¯• SSH è¿æ¥
                success, _ = self.run_command("ssh -T git@github.com 2>&1", cwd=".")
                # SSH æµ‹è¯•æ€»æ˜¯ä¼š"å¤±è´¥"ï¼ˆè¿”å› 1ï¼‰ï¼Œä½†å¦‚æœè®¤è¯æˆåŠŸä¼šæœ‰ "successfully authenticated" æ¶ˆæ¯
                # è¿™é‡Œæˆ‘ä»¬å‡è®¾ SSH å·²é…ç½®å¥½
                return True

        return False

    def check_and_push_unpushed_commits(self) -> bool:
        """æ£€æŸ¥å¹¶æ¨é€æœªæ¨é€çš„ commits"""

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ¨é€çš„ commits
        success, output = self.run_command("git log origin/main..HEAD --oneline 2>/dev/null || git log --oneline")

        if not success:
            return False

        unpushed_commits = output.strip().split('\n') if output.strip() else []

        if not unpushed_commits or (len(unpushed_commits) == 1 and not unpushed_commits[0]):
            logger.info("ğŸ“­ æ²¡æœ‰æœªæ¨é€çš„ commits")
            return False

        logger.info(f"ğŸ“¦ å‘ç° {len(unpushed_commits)} ä¸ªæœªæ¨é€çš„ commits")
        for commit in unpushed_commits[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            logger.info(f"   {commit}")

        # å°è¯•è®¾ç½®è®¤è¯
        self.setup_git_auth()

        # å°è¯•æ¨é€
        logger.info("ğŸš€ å°è¯•æ¨é€æœªæ¨é€çš„ commits...")

        # è·å–å½“å‰åˆ†æ”¯
        success, current_branch = self.run_command("git branch --show-current")
        if not success:
            logger.error("æ— æ³•è·å–å½“å‰åˆ†æ”¯")
            return False

        current_branch = current_branch.strip()

        # æ¨é€
        success, output = self.run_command(f'git push -u origin {current_branch}')

        if success:
            logger.info("âœ… æœªæ¨é€çš„ commits å·²æˆåŠŸæ¨é€")

            # æ›´æ–°çŠ¶æ€ - æ¯ä¸ªæœªæ¨é€çš„ commit å¯¹åº”ä¸€ä¸ªæ¨¡å—
            commits_pushed = len(unpushed_commits)
            self.state['current_module_index'] = min(
                self.state['current_module_index'] + commits_pushed,
                len(MODULES)
            )
            self.state['total_commits'] += commits_pushed
            self.save_state()

            return True
        else:
            logger.error("âŒ æ¨é€å¤±è´¥")
            logger.error(f"é”™è¯¯: {output}")

            # å¦‚æœæ˜¯è®¤è¯é—®é¢˜ï¼Œç»™å‡ºæç¤º
            if "Permission denied" in output or "could not read Username" in output:
                logger.error("\n" + "=" * 80)
                logger.error("ğŸ” æ¨é€å¤±è´¥ï¼šéœ€è¦é…ç½® GitHub è®¤è¯")
                logger.error("=" * 80)
                logger.error("\nå¿«é€Ÿè§£å†³æ–¹æ¡ˆï¼ˆé€‰æ‹©ä¸€ç§ï¼‰ï¼š")
                logger.error("\næ–¹æ³• 1: ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰")
                logger.error("  1. ç¼–è¾‘æ–‡ä»¶: GITHUB_TOKEN.env")
                logger.error("  2. å¡«å†™ä½ çš„ GitHub token")
                logger.error("  3. è¿è¡Œ: source GITHUB_TOKEN.env")
                logger.error("  4. é‡å¯æ­¤è„šæœ¬")
                logger.error("\næ–¹æ³• 2: ç›´æ¥é…ç½® Git URL")
                logger.error("  cd interview_assistant")
                logger.error("  git remote set-url origin https://<TOKEN>@github.com/q1q1-spefic/interview_assistant.git")
                logger.error("\næ–¹æ³• 3: è¿è¡Œå¿«é€Ÿè®¤è¯è„šæœ¬")
                logger.error("  ./quick_auth.sh")
                logger.error("\nè¯¦ç»†æ–‡æ¡£:")
                logger.error("  - GITHUB_AUTH_QUICKFIX.md")
                logger.error("  - ./setup_github_auth.sh")
                logger.error("\n" + "=" * 80)
                logger.error("\nâ³ ç³»ç»Ÿå°†åœ¨ä¸‹æ¬¡æ£€æŸ¥æ—¶è‡ªåŠ¨é‡è¯•æ¨é€...")
                logger.error("=" * 80 + "\n")

            return False

    def execute_once(self) -> bool:
        """æ‰§è¡Œä¸€æ¬¡æäº¤"""

        # æ£€æŸ¥æ˜¯å¦åˆå§‹åŒ–
        if not self.state['initialized']:
            logger.error("âŒ ä»“åº“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ --init")
            return False

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æœªæ¨é€çš„ commits
        if self.check_and_push_unpushed_commits():
            logger.info("âœ… å·²å¤„ç†æœªæ¨é€çš„ commits")
            # æˆåŠŸæ¨é€åï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å—

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æäº¤
        if not self.should_commit_now():
            return False

        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæäº¤çš„æ¨¡å—
        if self.state['current_module_index'] >= len(MODULES):
            logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å—å·²æäº¤å®Œæˆï¼")
            return False

        # è·å–ä¸‹ä¸€ä¸ªæ¨¡å—
        module = MODULES[self.state['current_module_index']]

        # æäº¤
        return self.commit_module(module)

    def run_forever(self):
        """æ°¸ä¹…è¿è¡Œ"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¤– GitHub æŒ¤ç‰™è†å¼å‘å¸ƒç³»ç»Ÿ - æ°¸ä¹…è¿è¡Œæ¨¡å¼")
        logger.info("=" * 80)
        logger.info(f"ä»“åº“: {CONFIG['repo_url']}")
        logger.info(f"æ£€æŸ¥é—´éš”: {CONFIG['check_interval_hours']} å°æ—¶")
        logger.info(f"æ¯æ—¥æäº¤: {CONFIG['commits_per_day']['min']}-{CONFIG['commits_per_day']['max']} æ¬¡")
        logger.info("=" * 80)

        try:
            while True:
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if self.state['current_module_index'] >= len(MODULES):
                    logger.info("\nğŸ‰ æ‰€æœ‰æ¨¡å—å·²æäº¤å®Œæˆï¼ç³»ç»Ÿé€€å‡ºã€‚")
                    break

                # æ‰§è¡Œä¸€æ¬¡
                self.execute_once()

                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                wait_hours = CONFIG['check_interval_hours']
                wait_minutes = wait_hours * 60 + random.randint(-30, 30)

                next_check = datetime.now() + timedelta(minutes=wait_minutes)
                logger.info(f"\nâ° ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {next_check.strftime('%Y-%m-%d %H:%M:%S')}")
                logger.info(f"   (ç­‰å¾… {wait_minutes} åˆ†é’Ÿ)\n")

                time.sleep(wait_minutes * 60)

        except KeyboardInterrupt:
            logger.info("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­...")
        finally:
            logger.info("âœ… ç³»ç»Ÿå·²å…³é—­")

    def print_status(self):
        """æ‰“å°å½“å‰çŠ¶æ€"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š å‘å¸ƒçŠ¶æ€")
        logger.info("=" * 80)
        logger.info(f"ä»“åº“: {CONFIG['repo_url']}")
        logger.info(f"åˆå§‹åŒ–: {'âœ…' if self.state['initialized'] else 'âŒ'}")
        logger.info(f"æ€»æ¨¡å—æ•°: {len(MODULES)}")
        logger.info(f"å·²å®Œæˆ: {self.state['current_module_index']}/{len(MODULES)}")
        logger.info(f"æ€»æäº¤æ•°: {self.state['total_commits']}")
        logger.info(f"ä»Šæ—¥æäº¤: {self.state['commits_today']}/{CONFIG['commits_per_day']['max']}")

        if self.state.get('last_commit_date'):
            logger.info(f"ä¸Šæ¬¡æäº¤: {self.state['last_commit_date']}")

        if self.state['current_module_index'] < len(MODULES):
            next_module = MODULES[self.state['current_module_index']]
            logger.info(f"\nä¸‹ä¸€ä¸ªæ¨¡å—: {next_module['name']}")
            logger.info(f"  {next_module['description']}")
            logger.info(f"  æ–‡ä»¶æ•°: {len(next_module['files'])}")

        logger.info("\nå·²å®Œæˆæ¨¡å—:")
        for module_name in self.state['completed_modules'][-5:]:
            logger.info(f"  âœ… {module_name}")

        logger.info("=" * 80 + "\n")

# ==================== CLI ====================

def main():
    parser = argparse.ArgumentParser(
        description='GitHub æŒ¤ç‰™è†å¼å‘å¸ƒç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--init', action='store_true', help='åˆå§‹åŒ– Git ä»“åº“')
    parser.add_argument('--once', action='store_true', help='æ‰§è¡Œä¸€æ¬¡æäº¤')
    parser.add_argument('--forever', action='store_true', help='æ°¸ä¹…è¿è¡Œ')
    parser.add_argument('--status', action='store_true', help='æŸ¥çœ‹çŠ¶æ€')

    args = parser.parse_args()

    publisher = GitHubGradualPublisher()

    # åˆå§‹åŒ–
    if args.init:
        publisher.init_repository()
        return 0

    # æŸ¥çœ‹çŠ¶æ€
    if args.status:
        publisher.print_status()
        return 0

    # é»˜è®¤å•æ¬¡è¿è¡Œ
    if not args.once and not args.forever:
        args.once = True

    # æ‰§è¡Œ
    if args.once:
        publisher.execute_once()
    elif args.forever:
        publisher.run_forever()

    return 0

if __name__ == "__main__":
    exit(main())
